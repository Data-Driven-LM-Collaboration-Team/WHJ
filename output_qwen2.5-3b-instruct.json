{
  "model": "qwen2.5-3b-instruct",
  "dataset": "/home/seki/AgenticMemory/data/locomo10.json",
  "total_questions": 304,
  "category_distribution": {
    "2": 63,
    "3": 13,
    "1": 43,
    "4": 114,
    "5": 71
  },
  "aggregate_metrics": {
    "overall": {
      "exact_match": {
        "mean": 0.09539473684210527,
        "std": 0.2942437452561613,
        "median": 0.0,
        "min": 0,
        "max": 1,
        "count": 304
      },
      "f1": {
        "mean": 0.23339037187626144,
        "std": 0.3316822301914821,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 304
      },
      "rouge1_f": {
        "mean": 0.26901188023706607,
        "std": 0.3304074035246394,
        "median": 0.13793103448275862,
        "min": 0.0,
        "max": 1.0,
        "count": 304
      },
      "rouge2_f": {
        "mean": 0.14156529599328477,
        "std": 0.29338657110817834,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 304
      },
      "rougeL_f": {
        "mean": 0.2654615509097285,
        "std": 0.33067494207308445,
        "median": 0.12060606060606062,
        "min": 0.0,
        "max": 1.0,
        "count": 304
      },
      "bleu1": {
        "mean": 0.19274619253485403,
        "std": 0.31046412722469297,
        "median": 0.01628882737881577,
        "min": 0,
        "max": 1.0,
        "count": 304
      },
      "bleu2": {
        "mean": 0.13835766502863026,
        "std": 0.2691722945910337,
        "median": 0.006131635747084883,
        "min": 0,
        "max": 1.0,
        "count": 304
      },
      "bleu3": {
        "mean": 0.11128771922696279,
        "std": 0.23701819435141622,
        "median": 0.005048171600311877,
        "min": 0,
        "max": 1.0,
        "count": 304
      },
      "bleu4": {
        "mean": 0.09359108912643203,
        "std": 0.2166622814379597,
        "median": 0.0036500102211835177,
        "min": 0,
        "max": 1.0,
        "count": 304
      },
      "bert_precision": {
        "mean": 0.8705528854931656,
        "std": 0.05725336434971232,
        "median": 0.8638516366481781,
        "min": 0.7599731683731079,
        "max": 1.000000238418579,
        "count": 304
      },
      "bert_recall": {
        "mean": 0.8765847141805448,
        "std": 0.05988031488344109,
        "median": 0.8631082773208618,
        "min": 0.7209846377372742,
        "max": 1.000000238418579,
        "count": 304
      },
      "bert_f1": {
        "mean": 0.8730536497345096,
        "std": 0.05497184823485382,
        "median": 0.8615693747997284,
        "min": 0.7703670859336853,
        "max": 1.000000238418579,
        "count": 304
      },
      "meteor": {
        "mean": 0.18702416667151284,
        "std": 0.30556675667223004,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9993141289437586,
        "count": 304
      },
      "sbert_similarity": {
        "mean": 0.43597581643974226,
        "std": 0.3125146435770985,
        "median": 0.3785206079483032,
        "min": -0.060942042618989944,
        "max": 1.000000238418579,
        "count": 304
      }
    },
    "category_1": {
      "exact_match": {
        "mean": 0.046511627906976744,
        "std": 0.21308263231644636,
        "median": 0,
        "min": 0,
        "max": 1,
        "count": 43
      },
      "f1": {
        "mean": 0.19575205156600506,
        "std": 0.2749952278807772,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 43
      },
      "rouge1_f": {
        "mean": 0.19124368555501106,
        "std": 0.2774797790375294,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 43
      },
      "rouge2_f": {
        "mean": 0.04245818780702502,
        "std": 0.12101369992546268,
        "median": 0.0,
        "min": 0.0,
        "max": 0.5714285714285715,
        "count": 43
      },
      "rougeL_f": {
        "mean": 0.187386261868946,
        "std": 0.27748476652599763,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 43
      },
      "bleu1": {
        "mean": 0.12430723943712364,
        "std": 0.23178803095007308,
        "median": 0.015981965301676893,
        "min": 0,
        "max": 1.0,
        "count": 43
      },
      "bleu2": {
        "mean": 0.05957527273884268,
        "std": 0.10825955065622941,
        "median": 0.00559717078549556,
        "min": 0,
        "max": 0.40451991747794525,
        "count": 43
      },
      "bleu3": {
        "mean": 0.04195458772307807,
        "std": 0.0788151942733941,
        "median": 0.0040676123867415155,
        "min": 0,
        "max": 0.301194211912202,
        "count": 43
      },
      "bleu4": {
        "mean": 0.03096072290628692,
        "std": 0.061579518730026865,
        "median": 0.0032047574588556275,
        "min": 0,
        "max": 0.301194211912202,
        "count": 43
      },
      "bert_precision": {
        "mean": 0.8761918392292288,
        "std": 0.06189519366037933,
        "median": 0.868899405002594,
        "min": 0.7806365489959717,
        "max": 1.0,
        "count": 43
      },
      "bert_recall": {
        "mean": 0.8595695883728737,
        "std": 0.06039082449229167,
        "median": 0.8444781303405762,
        "min": 0.769542396068573,
        "max": 1.0,
        "count": 43
      },
      "bert_f1": {
        "mean": 0.8672462161197219,
        "std": 0.05721611210112626,
        "median": 0.860112726688385,
        "min": 0.7980694770812988,
        "max": 1.0,
        "count": 43
      },
      "meteor": {
        "mean": 0.07138726316940588,
        "std": 0.13382909629468664,
        "median": 0.0,
        "min": 0.0,
        "max": 0.5,
        "count": 43
      },
      "sbert_similarity": {
        "mean": 0.41638237054914584,
        "std": 0.2556539906723997,
        "median": 0.4073336720466614,
        "min": -0.0034282305277884007,
        "max": 1.0000001192092896,
        "count": 43
      }
    },
    "category_2": {
      "exact_match": {
        "mean": 0.015873015873015872,
        "std": 0.12598815766974242,
        "median": 0,
        "min": 0,
        "max": 1,
        "count": 63
      },
      "f1": {
        "mean": 0.10141093474426807,
        "std": 0.22368908401220852,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 63
      },
      "rouge1_f": {
        "mean": 0.25723879295307867,
        "std": 0.2553807552791701,
        "median": 0.22222222222222224,
        "min": 0.0,
        "max": 1.0,
        "count": 63
      },
      "rouge2_f": {
        "mean": 0.09636501065072493,
        "std": 0.21982661294686875,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 63
      },
      "rougeL_f": {
        "mean": 0.25723879295307867,
        "std": 0.2553807552791701,
        "median": 0.22222222222222224,
        "min": 0.0,
        "max": 1.0,
        "count": 63
      },
      "bleu1": {
        "mean": 0.07537539291518126,
        "std": 0.1869010553306008,
        "median": 0,
        "min": 0,
        "max": 1.0,
        "count": 63
      },
      "bleu2": {
        "mean": 0.05445018797650075,
        "std": 0.16642342986794056,
        "median": 0,
        "min": 0,
        "max": 1.0,
        "count": 63
      },
      "bleu3": {
        "mean": 0.032038484790049566,
        "std": 0.10266534333295828,
        "median": 0,
        "min": 0,
        "max": 0.63287829698514,
        "count": 63
      },
      "bleu4": {
        "mean": 0.0223098080675529,
        "std": 0.06729733511061234,
        "median": 0,
        "min": 0,
        "max": 0.3976353643835253,
        "count": 63
      },
      "bert_precision": {
        "mean": 0.8409231059134953,
        "std": 0.047587127644888046,
        "median": 0.8467268347740173,
        "min": 0.7599731683731079,
        "max": 0.9997200965881348,
        "count": 63
      },
      "bert_recall": {
        "mean": 0.8671780039393713,
        "std": 0.05159598053173365,
        "median": 0.8533577919006348,
        "min": 0.7611851692199707,
        "max": 0.9997200965881348,
        "count": 63
      },
      "bert_f1": {
        "mean": 0.8533539696345254,
        "std": 0.04498739073294743,
        "median": 0.8518795371055603,
        "min": 0.7703670859336853,
        "max": 0.9997200965881348,
        "count": 63
      },
      "meteor": {
        "mean": 0.05443229877699673,
        "std": 0.16801892991024428,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9375,
        "count": 63
      },
      "sbert_similarity": {
        "mean": 0.5484808042408928,
        "std": 0.23120133922232436,
        "median": 0.6087161302566528,
        "min": 0.11516489088535309,
        "max": 1.0000001192092896,
        "count": 63
      }
    },
    "category_3": {
      "exact_match": {
        "mean": 0,
        "std": 0.0,
        "median": 0,
        "min": 0,
        "max": 0,
        "count": 13
      },
      "f1": {
        "mean": 0.060022839457464255,
        "std": 0.06342272890697617,
        "median": 0.05263157894736842,
        "min": 0.0,
        "max": 0.16666666666666669,
        "count": 13
      },
      "rouge1_f": {
        "mean": 0.10047454783457548,
        "std": 0.0860152132455388,
        "median": 0.0975609756097561,
        "min": 0.0,
        "max": 0.25,
        "count": 13
      },
      "rouge2_f": {
        "mean": 0.006410256410256411,
        "std": 0.023112508176051216,
        "median": 0.0,
        "min": 0.0,
        "max": 0.08333333333333334,
        "count": 13
      },
      "rougeL_f": {
        "mean": 0.10047454783457548,
        "std": 0.0860152132455388,
        "median": 0.0975609756097561,
        "min": 0.0,
        "max": 0.25,
        "count": 13
      },
      "bleu1": {
        "mean": 0.08139362241434935,
        "std": 0.070986104168534,
        "median": 0.08333333333333333,
        "min": 0,
        "max": 0.25,
        "count": 13
      },
      "bleu2": {
        "mean": 0.024865167584772516,
        "std": 0.023259965173476074,
        "median": 0.016854996561581053,
        "min": 0,
        "max": 0.07372097807744855,
        "count": 13
      },
      "bleu3": {
        "mean": 0.014153236118441978,
        "std": 0.011871752629907332,
        "median": 0.011280777824436245,
        "min": 0,
        "max": 0.04033183084278514,
        "count": 13
      },
      "bleu4": {
        "mean": 0.01052309558613228,
        "std": 0.00905189332769807,
        "median": 0.00913442366656447,
        "min": 0,
        "max": 0.03303164318013808,
        "count": 13
      },
      "bert_precision": {
        "mean": 0.8415702398006732,
        "std": 0.0241143740156865,
        "median": 0.8415875434875488,
        "min": 0.7942562699317932,
        "max": 0.8798983097076416,
        "count": 13
      },
      "bert_recall": {
        "mean": 0.8561888658083402,
        "std": 0.028682918404619926,
        "median": 0.8552323579788208,
        "min": 0.8025656342506409,
        "max": 0.9065686464309692,
        "count": 13
      },
      "bert_f1": {
        "mean": 0.8486561408409705,
        "std": 0.02338027306586801,
        "median": 0.854831874370575,
        "min": 0.7998224496841431,
        "max": 0.8781154751777649,
        "count": 13
      },
      "meteor": {
        "mean": 0.07433830277073006,
        "std": 0.10323973273835083,
        "median": 0.056818181818181816,
        "min": 0.0,
        "max": 0.3348214285714286,
        "count": 13
      },
      "sbert_similarity": {
        "mean": 0.3718742292660933,
        "std": 0.12648796271834106,
        "median": 0.43282410502433777,
        "min": 0.07151463627815247,
        "max": 0.5183714032173157,
        "count": 13
      }
    },
    "category_4": {
      "exact_match": {
        "mean": 0.06140350877192982,
        "std": 0.24112889804895893,
        "median": 0.0,
        "min": 0,
        "max": 1,
        "count": 114
      },
      "f1": {
        "mean": 0.2723567234609676,
        "std": 0.30855221227175583,
        "median": 0.1702898550724638,
        "min": 0.0,
        "max": 1.0,
        "count": 114
      },
      "rouge1_f": {
        "mean": 0.2794551304530038,
        "std": 0.3128795935666387,
        "median": 0.1763565891472868,
        "min": 0.0,
        "max": 1.0,
        "count": 114
      },
      "rouge2_f": {
        "mean": 0.1669442862083966,
        "std": 0.2956030818915183,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 114
      },
      "rougeL_f": {
        "mean": 0.2714425787248474,
        "std": 0.3134818449185013,
        "median": 0.14285714285714285,
        "min": 0.0,
        "max": 1.0,
        "count": 114
      },
      "bleu1": {
        "mean": 0.21686022438157354,
        "std": 0.28162072990080844,
        "median": 0.10488116360940265,
        "min": 0,
        "max": 1.0,
        "count": 114
      },
      "bleu2": {
        "mean": 0.15978707855444868,
        "std": 0.2581253360736822,
        "median": 0.03174223389555486,
        "min": 0,
        "max": 1.0,
        "count": 114
      },
      "bleu3": {
        "mean": 0.1251553622704924,
        "std": 0.2140725472803534,
        "median": 0.023660663952059374,
        "min": 0,
        "max": 1.0,
        "count": 114
      },
      "bleu4": {
        "mean": 0.10240176675654115,
        "std": 0.19386198273072752,
        "median": 0.01701890837969517,
        "min": 0,
        "max": 1.0,
        "count": 114
      },
      "bert_precision": {
        "mean": 0.8662302473135162,
        "std": 0.05250770407709261,
        "median": 0.8568221926689148,
        "min": 0.772576093673706,
        "max": 1.000000238418579,
        "count": 114
      },
      "bert_recall": {
        "mean": 0.8825170481414125,
        "std": 0.054434066833312096,
        "median": 0.8726131916046143,
        "min": 0.7209846377372742,
        "max": 1.000000238418579,
        "count": 114
      },
      "bert_f1": {
        "mean": 0.8739217143309744,
        "std": 0.05060755648957404,
        "median": 0.8587685525417328,
        "min": 0.7957022786140442,
        "max": 1.000000238418579,
        "count": 114
      },
      "meteor": {
        "mean": 0.24888190875857386,
        "std": 0.30734147571839154,
        "median": 0.10589592793865853,
        "min": 0.0,
        "max": 0.9921875,
        "count": 114
      },
      "sbert_similarity": {
        "mean": 0.41630919852800535,
        "std": 0.2903152084336059,
        "median": 0.34253358840942383,
        "min": -0.03339630737900734,
        "max": 1.0000001192092896,
        "count": 114
      }
    },
    "category_5": {
      "exact_match": {
        "mean": 0.2676056338028169,
        "std": 0.44586181327765156,
        "median": 0,
        "min": 0,
        "max": 1,
        "count": 71
      },
      "f1": {
        "mean": 0.3424715853050567,
        "std": 0.44210943897070254,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 71
      },
      "rouge1_f": {
        "mean": 0.34064838258685554,
        "std": 0.44134897363830083,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 71
      },
      "rouge2_f": {
        "mean": 0.22569253907282077,
        "std": 0.4004435852155208,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 71
      },
      "rougeL_f": {
        "mean": 0.34064838258685554,
        "std": 0.44134897363830083,
        "median": 0.0,
        "min": 0.0,
        "max": 1.0,
        "count": 71
      },
      "bleu1": {
        "mean": 0.32001125084868964,
        "std": 0.43612011847133647,
        "median": 0,
        "min": 0,
        "max": 1.0,
        "count": 71
      },
      "bleu2": {
        "mean": 0.24689658400851583,
        "std": 0.38622414367596913,
        "median": 0,
        "min": 0,
        "max": 1.0,
        "count": 71
      },
      "bleu3": {
        "mean": 0.21911678116556804,
        "std": 0.3655681889196416,
        "median": 0,
        "min": 0,
        "max": 1.0,
        "count": 71
      },
      "bleu4": {
        "mean": 0.19583465420202473,
        "std": 0.3423904518695037,
        "median": 0,
        "min": 0,
        "max": 1.0,
        "count": 71
      },
      "bert_precision": {
        "mean": 0.9056762129488126,
        "std": 0.05555860759252367,
        "median": 0.8808639645576477,
        "min": 0.8480530381202698,
        "max": 1.000000238418579,
        "count": 71
      },
      "bert_recall": {
        "mean": 0.889445743930172,
        "std": 0.0740980852359779,
        "median": 0.8652691841125488,
        "min": 0.7347403764724731,
        "max": 1.000000238418579,
        "count": 71
      },
      "bert_f1": {
        "mean": 0.8971241813310435,
        "std": 0.06345257012890929,
        "median": 0.8705790042877197,
        "min": 0.7939961552619934,
        "max": 1.000000238418579,
        "count": 71
      },
      "meteor": {
        "mean": 0.29602146470996826,
        "std": 0.41161370570110856,
        "median": 0.0,
        "min": 0.0,
        "max": 0.9993141289437586,
        "count": 71
      },
      "sbert_similarity": {
        "mean": 0.391328196961131,
        "std": 0.4270239933744087,
        "median": 0.12110546976327896,
        "min": -0.060942042618989944,
        "max": 1.000000238418579,
        "count": 71
      }
    }
  },
  "individual_results": [
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ support group?",
      "prediction": "8-May-2023",
      "reference": "7 May 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.9099240899085999,
        "bert_recall": 0.9524462819099426,
        "bert_f1": 0.9306997060775757,
        "meteor": 0.0,
        "sbert_similarity": 0.8462123870849609
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie paint a sunrise?",
      "prediction": "10oct2023",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7965106964111328,
        "bert_recall": 0.9024755358695984,
        "bert_f1": 0.8461886048316956,
        "meteor": 0.0,
        "sbert_similarity": 0.2384667694568634
      }
    },
    {
      "sample_id": 0,
      "question": "What fields would Caroline be likely to pursue in her educaton?",
      "prediction": "career options",
      "reference": "Psychology, counseling certification",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8461048603057861,
        "bert_recall": 0.8304933905601501,
        "bert_f1": 0.8382264375686646,
        "meteor": 0.0,
        "sbert_similarity": 0.3410683870315552
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline research?",
      "prediction": "Cool! What did it look like?",
      "reference": "Adoption agencies",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8090447187423706,
        "bert_recall": 0.8222025036811829,
        "bert_f1": 0.8155704736709595,
        "meteor": 0.0,
        "sbert_similarity": 0.03908083960413933
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's identity?",
      "prediction": "Caroline",
      "reference": "Transgender woman",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.9238872528076172,
        "bert_recall": 0.8625736832618713,
        "bert_f1": 0.8921782970428467,
        "meteor": 0.0,
        "sbert_similarity": 0.31666386127471924
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie run a charity race?",
      "prediction": "25-May-2023",
      "reference": "The sunday before 25 May 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8685015439987183,
        "bert_recall": 0.8257270455360413,
        "bert_f1": 0.8465743064880371,
        "meteor": 0.0,
        "sbert_similarity": 0.8065865635871887
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie planning on going camping?",
      "prediction": "2023-08-17",
      "reference": "June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7599731683731079,
        "bert_recall": 0.8136026263237,
        "bert_f1": 0.78587406873703,
        "meteor": 0.0,
        "sbert_similarity": 0.753380298614502
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's relationship status?",
      "prediction": "Single",
      "reference": "Single",
      "category": 1,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline give a speech at a school?",
      "prediction": "8-56pm-20jul23",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8045839071273804,
        "bert_recall": 0.8058673143386841,
        "bert_f1": 0.8052250742912292,
        "meteor": 0.0,
        "sbert_similarity": 0.1949617862701416
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline meet up with her friends, family, and mentors?",
      "prediction": "6-jun-2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8599804639816284,
        "bert_recall": 0.8439297080039978,
        "bert_f1": 0.8518795371055603,
        "meteor": 0.0,
        "sbert_similarity": 0.6696328520774841
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Caroline had her current group of friends for?",
      "prediction": "9 June",
      "reference": "4 years",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8894580602645874,
        "bert_recall": 0.8984744548797607,
        "bert_f1": 0.8939435482025146,
        "meteor": 0.0,
        "sbert_similarity": 0.3437242805957794
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Caroline move from 4 years ago?",
      "prediction": "forest",
      "reference": "Sweden",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.996066689491272,
        "bert_recall": 0.996066689491272,
        "bert_f1": 0.996066689491272,
        "meteor": 0.0,
        "sbert_similarity": 0.27813100814819336
      }
    },
    {
      "sample_id": 0,
      "question": "How long ago was Caroline's 18th birthday?",
      "prediction": "2y",
      "reference": "10 years ago",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7797731161117554,
        "bert_recall": 0.7611851692199707,
        "bert_f1": 0.7703670859336853,
        "meteor": 0.0,
        "sbert_similarity": 0.11516489088535309
      }
    },
    {
      "sample_id": 0,
      "question": "What career path has Caroline decided to persue?",
      "prediction": "No career path has been decided yet.",
      "reference": "counseling or mental health for Transgender people",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8439024686813354,
        "bert_recall": 0.7964823246002197,
        "bert_f1": 0.8195070028305054,
        "meteor": 0.0,
        "sbert_similarity": 0.10918131470680237
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline still want to pursue counseling as a career if she hadn't received support growing up?",
      "prediction": "Based on the context, it is clear that Caroline would still want to pursue counseling as a career even without receiving support growing up. The context shows her own journey where she found support crucial, leading her to become passionate about helping others on their own journeys.",
      "reference": "Likely no",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7970980405807495,
        "bert_recall": 0.8025656342506409,
        "bert_f1": 0.7998224496841431,
        "meteor": 0.0,
        "sbert_similarity": 0.07151463627815247
      }
    },
    {
      "sample_id": 0,
      "question": "What activities does Melanie partake in?",
      "prediction": "painting",
      "reference": "pottery, camping, painting, swimming",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.0024787521766663585,
        "bleu2": 0.000783850263336577,
        "bleu3": 0.0005422918887392082,
        "bleu4": 0.0004407913958354948,
        "bert_precision": 0.8212592601776123,
        "bert_recall": 0.7872121334075928,
        "bert_f1": 0.8038753271102905,
        "meteor": 0.0,
        "sbert_similarity": 0.433554470539093
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie sign up for a pottery class?",
      "prediction": "15-jul-23",
      "reference": "2 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8194011449813843,
        "bert_recall": 0.8453108072280884,
        "bert_f1": 0.8321543335914612,
        "meteor": 0.0,
        "sbert_similarity": 0.2921246886253357
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline going to the transgender conference?",
      "prediction": "3-jun-2023",
      "reference": "July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8407570719718933,
        "bert_recall": 0.9325780272483826,
        "bert_f1": 0.884290337562561,
        "meteor": 0.0,
        "sbert_similarity": 0.7743397355079651
      }
    },
    {
      "sample_id": 0,
      "question": "Where has Melanie camped?",
      "prediction": "The mountains",
      "reference": "beach, mountains, forest",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.11156508007421491,
        "bleu2": 0.04989342059223037,
        "bleu3": 0.03883455907572571,
        "bleu4": 0.03336574130316504,
        "bert_precision": 0.9250825643539429,
        "bert_recall": 0.8577304482460022,
        "bert_f1": 0.8901342153549194,
        "meteor": 0.0,
        "sbert_similarity": 0.6393359303474426
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's kids like?",
      "prediction": "Wow, fantastic, Caroline! Bet the atmosphere was incredible. Oh yeah, we went to the beach recently. It was awesome! The kids had such a blast.",
      "reference": "dinosaurs, nature",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.030303030303030304,
        "bleu2": 0.00973123680201904,
        "bleu3": 0.007080135152914422,
        "bleu4": 0.005648892151960285,
        "bert_precision": 0.8025554418563843,
        "bert_recall": 0.7936333417892456,
        "bert_f1": 0.7980694770812988,
        "meteor": 0.0,
        "sbert_similarity": 0.1262102574110031
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the museum?",
      "prediction": "8-18-23",
      "reference": "5 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7822551131248474,
        "bert_recall": 0.8178468942642212,
        "bert_f1": 0.7996551990509033,
        "meteor": 0.0,
        "sbert_similarity": 0.26459163427352905
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline have a picnic?",
      "prediction": "8:18 pm on 6 July, 2023",
      "reference": "The week before 6 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.4615384615384615,
        "rouge2_f": 0.3636363636363636,
        "rougeL_f": 0.4615384615384615,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.8757824301719666,
        "bert_recall": 0.8922140598297119,
        "bert_f1": 0.8839218616485596,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.728199303150177
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline likely have Dr. Seuss books on her bookshelf?",
      "prediction": "Sounds great! What kind of books you got in your library?",
      "reference": "Yes, since she collects classic children's books",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1111111111111111,
        "rouge1_f": 0.10526315789473685,
        "rouge2_f": 0.0,
        "rougeL_f": 0.10526315789473685,
        "bleu1": 0.07692307692307693,
        "bleu2": 0.025318484177091663,
        "bleu3": 0.018733084686676876,
        "bleu4": 0.01553712569276035,
        "bert_precision": 0.8415875434875488,
        "bert_recall": 0.8733031153678894,
        "bert_f1": 0.8571520447731018,
        "meteor": 0.06756756756756757,
        "sbert_similarity": 0.37829509377479553
      }
    },
    {
      "sample_id": 0,
      "question": "What books has Melanie read?",
      "prediction": "\"Charlotte's Web\"",
      "reference": "\"Nothing is Impossible\", \"Charlotte's Web\"",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.301194211912202,
        "bleu2": 0.301194211912202,
        "bleu3": 0.301194211912202,
        "bleu4": 0.301194211912202,
        "bert_precision": 0.9526905417442322,
        "bert_recall": 0.914000928401947,
        "bert_f1": 0.9329447746276855,
        "meteor": 0.39893617021276595,
        "sbert_similarity": 0.7511486411094666
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to destress?",
      "prediction": "Running",
      "reference": "Running, pottery",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.04279677428117006,
        "bleu3": 0.02960813390314045,
        "bleu4": 0.024066394763145416,
        "bert_precision": 0.9080307483673096,
        "bert_recall": 0.8043123483657837,
        "bert_f1": 0.8530303835868835,
        "meteor": 0.0,
        "sbert_similarity": 0.5836724042892456
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ conference?",
      "prediction": "2023-07-12",
      "reference": "10 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7812943458557129,
        "bert_recall": 0.8105915784835815,
        "bert_f1": 0.7956733703613281,
        "meteor": 0.0,
        "sbert_similarity": 0.671085000038147
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie read the book \"nothing is impossible\"?",
      "prediction": "8jul23",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7807217836380005,
        "bert_recall": 0.8842549324035645,
        "bert_f1": 0.8292693495750427,
        "meteor": 0.0,
        "sbert_similarity": 0.24456553161144257
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline pursue writing as a career option?",
      "prediction": "No, based on the conversation, Caroline is considering various career options including exploring nature and spending time with her family, but not mentioned as a career option is writing.",
      "reference": "LIkely no; though she likes reading, she wants to be a counselor",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.05263157894736842,
        "rouge1_f": 0.0975609756097561,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0975609756097561,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.016854996561581053,
        "bleu3": 0.010173995989186396,
        "bleu4": 0.007434360163166208,
        "bert_precision": 0.8461064100265503,
        "bert_recall": 0.8552323579788208,
        "bert_f1": 0.8506448864936829,
        "meteor": 0.07299270072992702,
        "sbert_similarity": 0.43282410502433777
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the adoption meeting?",
      "prediction": "8-aug-23",
      "reference": "The friday before 15 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7836383581161499,
        "bert_recall": 0.781104326248169,
        "bert_f1": 0.7823692560195923,
        "meteor": 0.0,
        "sbert_similarity": 0.5189445614814758
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the pottery workshop?",
      "prediction": "15-07-2023",
      "reference": "The Friday before 15 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8271104097366333,
        "bert_recall": 0.8122082948684692,
        "bert_f1": 0.8195916414260864,
        "meteor": 0.0,
        "sbert_similarity": 0.5817322134971619
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered a member of the LGBTQ community?",
      "prediction": "Yes, based on the context, Melanie participates in LGBTQ advocacy efforts such as mentoring LGBTQ youth and discussing the importance of fighting for trans rights, indicating her membership within the LGBTQ community.",
      "reference": "Likely no, she does not refer to herself as part of it",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1,
        "rouge1_f": 0.09090909090909091,
        "rouge2_f": 0.0,
        "rougeL_f": 0.09090909090909091,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.01543033499620919,
        "bleu3": 0.009309785858239085,
        "bleu4": 0.006787181501568368,
        "bert_precision": 0.8396088480949402,
        "bert_recall": 0.870617151260376,
        "bert_f1": 0.854831874370575,
        "meteor": 0.07142857142857144,
        "sbert_similarity": 0.45224037766456604
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in June?",
      "prediction": "8:56 pm on 20 July, 2023",
      "reference": "The week before 27 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.15384615384615383,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615383,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.862930178642273,
        "bert_recall": 0.8628968000411987,
        "bert_f1": 0.8629134893417358,
        "meteor": 0.08333333333333333,
        "sbert_similarity": 0.6179395914077759
      }
    },
    {
      "sample_id": 0,
      "question": "What LGBTQ+ events has Caroline participated in?",
      "prediction": "LGBTQ+ pride parade, LGBTQ support group, LGBT pride event",
      "reference": "Pride parade, school speech, support group",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5333333333333333,
        "rouge2_f": 0.3076923076923077,
        "rougeL_f": 0.5333333333333333,
        "bleu1": 0.5454545454545454,
        "bleu2": 0.40451991747794525,
        "bleu3": 0.2664896291542936,
        "bleu4": 0.12278260149096115,
        "bert_precision": 0.8583070039749146,
        "bert_recall": 0.9034978747367859,
        "bert_f1": 0.8803228735923767,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.7495311498641968
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to a pride parade during the summer?",
      "prediction": "2023-07-14",
      "reference": "The week before 3 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7738662958145142,
        "bert_recall": 0.783359169960022,
        "bert_f1": 0.7785837650299072,
        "meteor": 0.0,
        "sbert_similarity": 0.6235678791999817
      }
    },
    {
      "sample_id": 0,
      "question": "What events has Caroline participated in to help children?",
      "prediction": "The context does not specify any events Caroline participated in to help children.",
      "reference": "Mentoring program, school speech",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8385781049728394,
        "bert_recall": 0.8307299613952637,
        "bert_f1": 0.8346356153488159,
        "meteor": 0.0,
        "sbert_similarity": 0.2972072660923004
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in July?",
      "prediction": "8:56 pm on 20 July, 2023",
      "reference": "two weekends before 17 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.30769230769230765,
        "rouge2_f": 0.1818181818181818,
        "rougeL_f": 0.30769230769230765,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.06900655593423542,
        "bleu3": 0.047098549390932394,
        "bleu4": 0.039281465090051315,
        "bert_precision": 0.8467268347740173,
        "bert_recall": 0.8623133897781372,
        "bert_f1": 0.8544490933418274,
        "meteor": 0.08333333333333333,
        "sbert_similarity": 0.5809721350669861
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a mentorship program?",
      "prediction": "17-Jul-2023",
      "reference": "The weekend before 17 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8722769021987915,
        "bert_recall": 0.8462834358215332,
        "bert_f1": 0.8590835928916931,
        "meteor": 0.0,
        "sbert_similarity": 0.6604872345924377
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie paint recently?",
      "prediction": "[a photo of a painting of a sunset with a palm tree]",
      "reference": "sunset",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.19999999999999998,
        "rouge1_f": 0.15384615384615385,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615385,
        "bleu1": 0.07142857142857141,
        "bleu2": 0.023440361546924773,
        "bleu3": 0.017300021018422027,
        "bleu4": 0.01428363257865929,
        "bert_precision": 0.7986164093017578,
        "bert_recall": 0.8376827836036682,
        "bert_f1": 0.8176832795143127,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.5890401601791382
      }
    },
    {
      "sample_id": 0,
      "question": "What activities has Melanie done with her family?",
      "prediction": "Family outings, playing games, hanging out, beach days at sunset.",
      "reference": "Pottery, painting, camping, museum, swimming, hiking",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.21428571428571425,
        "bleu2": 0.040599897147057515,
        "bleu3": 0.024859743585800658,
        "bleu4": 0.018798317647335087,
        "bert_precision": 0.8457726240158081,
        "bert_recall": 0.8365591764450073,
        "bert_f1": 0.8411406874656677,
        "meteor": 0.0,
        "sbert_similarity": 0.5134220123291016
      }
    },
    {
      "sample_id": 0,
      "question": "In what ways is Caroline participating in the LGBTQ community?",
      "prediction": "Involving herself in a new LGBTQ activist group, mentoring a transgender teen, and attending regular meetings, planning events, and campaigns to support the community.",
      "reference": "Joining activist group, going to pride parades, participating in an art show, mentoring program",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2777777777777778,
        "rouge1_f": 0.2631578947368421,
        "rouge2_f": 0.05555555555555555,
        "rougeL_f": 0.15789473684210525,
        "bleu1": 0.27586206896551724,
        "bleu2": 0.1719204765183758,
        "bleu3": 0.10543047858721523,
        "bleu4": 0.045298051905638646,
        "bert_precision": 0.8792004585266113,
        "bert_recall": 0.8766782879829407,
        "bert_f1": 0.8779376149177551,
        "meteor": 0.2842592592592592,
        "sbert_similarity": 0.6517009139060974
      }
    },
    {
      "sample_id": 0,
      "question": "How many times has Melanie gone to the beach in 2023?",
      "prediction": "2",
      "reference": 2,
      "category": 1,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999999403953552,
        "bert_recall": 0.9999999403953552,
        "bert_f1": 0.9999999403953552,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a new activist group?",
      "prediction": "8 may 2023",
      "reference": "The Tuesday before 20 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.12262648039048077,
        "bleu2": 0.04749303163563625,
        "bleu3": 0.044556965439969995,
        "bleu4": 0.0417991745584234,
        "bert_precision": 0.9077715277671814,
        "bert_recall": 0.8483811020851135,
        "bert_f1": 0.8770720958709717,
        "meteor": 0.08771929824561403,
        "sbert_similarity": 0.8025190234184265
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be more interested in going to a national park or a theme park?",
      "prediction": "theme park",
      "reference": "National park; she likes the outdoors",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.0410424993119494,
        "bleu2": 0.018354763685601443,
        "bleu3": 0.014286435890917338,
        "bleu4": 0.012274570264879268,
        "bert_precision": 0.8668108582496643,
        "bert_recall": 0.8436029553413391,
        "bert_f1": 0.8550494909286499,
        "meteor": 0.0,
        "sbert_similarity": 0.448770672082901
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of art does Caroline make?",
      "prediction": "Painting",
      "reference": "abstract art",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.9376604557037354,
        "bert_recall": 0.8577601909637451,
        "bert_f1": 0.8959324359893799,
        "meteor": 0.0,
        "sbert_similarity": 0.5710418224334717
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie's daughter's birthday?",
      "prediction": "2023-08-14",
      "reference": "13 August",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7789483070373535,
        "bert_recall": 0.8533577919006348,
        "bert_f1": 0.8144570589065552,
        "meteor": 0.0,
        "sbert_similarity": 0.4625770151615143
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline attend a pride parade in August?",
      "prediction": "8th August",
      "reference": "The Friday before 14 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.06766764161830635,
        "bleu2": 0.030261889307125377,
        "bleu3": 0.02355435073584915,
        "bleu4": 0.020237345084409754,
        "bert_precision": 0.8580500483512878,
        "bert_recall": 0.8147628307342529,
        "bert_f1": 0.8358463644981384,
        "meteor": 0.08928571428571427,
        "sbert_similarity": 0.6091524958610535
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered an ally to the transgender community?",
      "prediction": "Yes, based on the context, Melanie would be considered an ally to the transgender community as she supports Caroline's transition and shows appreciation for her efforts and contributions to LGBTQ advocacy.",
      "reference": "Yes, she is supportive",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.125,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.08571428571428572,
        "bleu2": 0.05020964452534338,
        "bleu3": 0.02048377122071517,
        "bleu4": 0.012430185041026947,
        "bert_precision": 0.8397210240364075,
        "bert_recall": 0.9065686464309692,
        "bert_f1": 0.8718653321266174,
        "meteor": 0.22388059701492538,
        "sbert_similarity": 0.46932199597358704
      }
    },
    {
      "sample_id": 0,
      "question": "Who supports Caroline when she has a negative experience?",
      "prediction": "Their love and encouragement",
      "reference": "Her mentors, family, and friends",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.22222222222222224,
        "rouge1_f": 0.22222222222222224,
        "rouge2_f": 0.0,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.11809163818525367,
        "bleu2": 0.043120969391201254,
        "bleu3": 0.036208407874557175,
        "bleu4": 0.037951271263104894,
        "bert_precision": 0.8688805103302002,
        "bert_recall": 0.875730574131012,
        "bert_f1": 0.8722921013832092,
        "meteor": 0.10204081632653061,
        "sbert_similarity": 0.4073336720466614
      }
    },
    {
      "sample_id": 0,
      "question": "What types of pottery have Melanie and her kids made?",
      "prediction": "Pottery and clay sculptures.",
      "reference": "bowls, cup",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8451368808746338,
        "bert_recall": 0.8476248979568481,
        "bert_f1": 0.8463791012763977,
        "meteor": 0.0,
        "sbert_similarity": 0.3158167600631714
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline and Melanie go to a pride fesetival together?",
      "prediction": "14th August",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7616962194442749,
        "bert_recall": 0.8456566333770752,
        "bert_f1": 0.8014835715293884,
        "meteor": 0.0,
        "sbert_similarity": 0.34716564416885376
      }
    },
    {
      "sample_id": 0,
      "question": "What would Caroline's political leaning likely be?",
      "prediction": "None of the provided context contains information about Caroline's political leaning.",
      "reference": "Liberal",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7942562699317932,
        "bert_recall": 0.8218591213226318,
        "bert_f1": 0.8078219890594482,
        "meteor": 0.0,
        "sbert_similarity": 0.2149447798728943
      }
    },
    {
      "sample_id": 0,
      "question": "What has Melanie painted?",
      "prediction": "a photo of a painting of a sunset with a palm tree\na photo of a painting of a sunset with a pink sky\na photo of a painting of a sunset with a purple flower landscape\na field of purple flowers with green leaves\na photo of a painting of a sunset with a purple sky",
      "reference": "Horse, sunset, sunrise",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1,
        "rouge1_f": 0.03333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.03333333333333333,
        "bleu1": 0.017543859649122806,
        "bleu2": 0.00559717078549556,
        "bleu3": 0.0040676123867415155,
        "bleu4": 0.0032047574588556275,
        "bert_precision": 0.7844031453132629,
        "bert_recall": 0.8262139558792114,
        "bert_f1": 0.8047658205032349,
        "meteor": 0.0,
        "sbert_similarity": 0.4233015477657318
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's pets' names?",
      "prediction": "Oscar",
      "reference": "Oliver, Luna, Bailey",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8971912860870361,
        "bert_recall": 0.7953620553016663,
        "bert_f1": 0.8432135581970215,
        "meteor": 0.0,
        "sbert_similarity": 0.19676248729228973
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline apply to adoption agencies?",
      "prediction": "3:31 pm on 23 august, 2023",
      "reference": "The week of 23 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.4615384615384615,
        "rouge2_f": 0.3636363636363636,
        "rougeL_f": 0.4615384615384615,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.8669835329055786,
        "bert_recall": 0.8799388408660889,
        "bert_f1": 0.8734131455421448,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.7408578395843506
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline draw a self-portrait?",
      "prediction": "10oct2023",
      "reference": "The week before 23 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8798951506614685,
        "bert_recall": 0.8188669085502625,
        "bert_f1": 0.8482848405838013,
        "meteor": 0.0,
        "sbert_similarity": 0.1788129210472107
      }
    },
    {
      "sample_id": 0,
      "question": "What subject have Caroline and Melanie both painted?",
      "prediction": "painting",
      "reference": "Sunsets",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8751156330108643,
        "bert_recall": 0.8036507368087769,
        "bert_f1": 0.8378620147705078,
        "meteor": 0.0,
        "sbert_similarity": 0.28051090240478516
      }
    },
    {
      "sample_id": 0,
      "question": "What symbols are important to Caroline?",
      "prediction": "The eagle and the rainbow flag",
      "reference": "Rainbow flag, transgender symbol",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444445,
        "rouge1_f": 0.4,
        "rouge2_f": 0.25,
        "rougeL_f": 0.4,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.25819888974716115,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.08633400213704504,
        "bert_precision": 0.8806005120277405,
        "bert_recall": 0.900477409362793,
        "bert_f1": 0.8904280662536621,
        "meteor": 0.11904761904761905,
        "sbert_similarity": 0.667179524898529
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline encounter people on a hike and have a negative experience?",
      "prediction": "10:37am-27June2023",
      "reference": "The week before 25 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8512614369392395,
        "bert_recall": 0.8633197546005249,
        "bert_f1": 0.8572481274604797,
        "meteor": 0.0,
        "sbert_similarity": 0.2743443250656128
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie make a plate in pottery class?",
      "prediction": "15-jul-23",
      "reference": "24 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8181319236755371,
        "bert_recall": 0.8456268310546875,
        "bert_f1": 0.8316522240638733,
        "meteor": 0.0,
        "sbert_similarity": 0.31528812646865845
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline be considered religious?",
      "prediction": "No, based on the provided context, Caroline does not appear to be considered religious. There is no mention of religious practices, beliefs, or discussions related to religion.",
      "reference": "Somewhat, but not extremely religious",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.13793103448275862,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.125,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.016854996561581053,
        "bleu3": 0.010173995989186396,
        "bleu4": 0.007434360163166208,
        "bert_precision": 0.8359830379486084,
        "bert_recall": 0.8473034501075745,
        "bert_f1": 0.8416051864624023,
        "meteor": 0.1388888888888889,
        "sbert_similarity": 0.47344109416007996
      }
    },
    {
      "sample_id": 0,
      "question": "What instruments does Melanie play?",
      "prediction": "No instruments.",
      "reference": "clarinet and violin",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8987426161766052,
        "bert_recall": 0.8273718953132629,
        "bert_f1": 0.8615818023681641,
        "meteor": 0.0,
        "sbert_similarity": 0.45639750361442566
      }
    },
    {
      "sample_id": 0,
      "question": "What musical artists/bands has Melanie seen?",
      "prediction": "Ed Sheeran's \"Perfect\"",
      "reference": "Summer Sounds, Matt Patterson",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7806365489959717,
        "bert_recall": 0.8444781303405762,
        "bert_f1": 0.8113033175468445,
        "meteor": 0.0,
        "sbert_similarity": 0.14386571943759918
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the park?",
      "prediction": "13-10-2023",
      "reference": "27 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8556653261184692,
        "bert_recall": 0.8983044624328613,
        "bert_f1": 0.8764665722846985,
        "meteor": 0.0,
        "sbert_similarity": 0.6454762816429138
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline's youth center putting on a talent show?",
      "prediction": "28-Aug-23",
      "reference": "September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7640132308006287,
        "bert_recall": 0.8070056438446045,
        "bert_f1": 0.7849211096763611,
        "meteor": 0.0,
        "sbert_similarity": 0.45442789793014526
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie likely enjoy the song \"The Four Seasons\" by Vivaldi?",
      "prediction": "Based on Melanie's expressed interest in classical music like Bach and Mozart, she might appreciate 'The Four Seasons' by Vivaldi.",
      "reference": "Yes; it's classical music",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666669,
        "rouge1_f": 0.23076923076923073,
        "rouge2_f": 0.08333333333333334,
        "rougeL_f": 0.23076923076923073,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.07372097807744855,
        "bleu3": 0.030172453991950343,
        "bleu4": 0.01851974703879588,
        "bert_precision": 0.8391090631484985,
        "bert_recall": 0.8721521496772766,
        "bert_f1": 0.8553115725517273,
        "meteor": 0.3348214285714286,
        "sbert_similarity": 0.44726261496543884
      }
    },
    {
      "sample_id": 0,
      "question": "What are some changes Caroline has faced during her transition journey?",
      "prediction": "Art's exploration and acceptance of imperfections during her transition.",
      "reference": "Changes to her body, losing unsupportive friends",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.125,
        "rouge1_f": 0.11764705882352941,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11764705882352941,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.03015113445777637,
        "bleu3": 0.022461584318318094,
        "bleu4": 0.018850319022747353,
        "bert_precision": 0.868899405002594,
        "bert_recall": 0.8503220677375793,
        "bert_f1": 0.8595103621482849,
        "meteor": 0.06944444444444445,
        "sbert_similarity": 0.3070634603500366
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do with her family on hikes?",
      "prediction": "Melanie enjoys hiking in the mountains and exploring forests with her family.",
      "reference": "Roast marshmallows, tell stories",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8649134039878845,
        "bert_recall": 0.8226766586303711,
        "bert_f1": 0.843266487121582,
        "meteor": 0.0,
        "sbert_similarity": 0.17628155648708344
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go biking with friends?",
      "prediction": "13-09-2023",
      "reference": "The weekend before 13 September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8217763900756836,
        "bert_recall": 0.8131442070007324,
        "bert_f1": 0.8174375295639038,
        "meteor": 0.0,
        "sbert_similarity": 0.6330372095108032
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been practicing art?",
      "prediction": "since 2016",
      "reference": "Since 2016",
      "category": 2,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9997200965881348,
        "bert_recall": 0.9997200965881348,
        "bert_f1": 0.9997200965881348,
        "meteor": 0.9375,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What personality traits might Melanie say Caroline has?",
      "prediction": "caring heart, supportive, inspiring, accepting",
      "reference": "Thoughtful, authentic, driven",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.25,
        "bleu2": 0.059761430466719695,
        "bleu3": 0.04033183084278514,
        "bleu4": 0.03303164318013808,
        "bert_precision": 0.8798983097076416,
        "bert_recall": 0.876339852809906,
        "bert_f1": 0.8781154751777649,
        "meteor": 0.0,
        "sbert_similarity": 0.5183714032173157
      }
    },
    {
      "sample_id": 0,
      "question": "What transgender-specific events has Caroline attended?",
      "prediction": "LGBTQ pride event, transgender conference",
      "reference": "Poetry reading, conference",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.08164965809277261,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.048549177170732344,
        "bert_precision": 0.8515130877494812,
        "bert_recall": 0.8780134916305542,
        "bert_f1": 0.8645602464675903,
        "meteor": 0.15625,
        "sbert_similarity": 0.27329790592193604
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Melanie read from Caroline's suggestion?",
      "prediction": "That book I read last year reminds me to always pursue my dreams, just like you are doing!",
      "reference": "\"Becoming Nicole\"",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8116050958633423,
        "bert_recall": 0.830088198184967,
        "bert_f1": 0.8207425475120544,
        "meteor": 0.0,
        "sbert_similarity": 0.14343613386154175
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's friend adopt a child?",
      "prediction": "10oct2023",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7965106964111328,
        "bert_recall": 0.9024755358695984,
        "bert_f1": 0.8461886048316956,
        "meteor": 0.0,
        "sbert_similarity": 0.2384667694568634
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie get hurt?",
      "prediction": "20 october 2023",
      "reference": "September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.8403416872024536,
        "bert_recall": 0.9285951852798462,
        "bert_f1": 0.8822669386863708,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.7736970782279968
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's family go on a roadtrip?",
      "prediction": "13-Oct-2023",
      "reference": "The weekend before 20 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8682457804679871,
        "bert_recall": 0.8436933755874634,
        "bert_f1": 0.8557935357093811,
        "meteor": 0.0,
        "sbert_similarity": 0.6786130666732788
      }
    },
    {
      "sample_id": 0,
      "question": "How many children does Melanie have?",
      "prediction": "[]",
      "reference": 3,
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8903661966323853,
        "bert_recall": 0.8903661966323853,
        "bert_f1": 0.8903661966323853,
        "meteor": 0.0,
        "sbert_similarity": 0.2892223298549652
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go on a hike after the roadtrip?",
      "prediction": "There is no mention of a hike or any trip after the roadtrip in the provided context.",
      "reference": "19 October 2023",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8124234676361084,
        "bert_recall": 0.804652988910675,
        "bert_f1": 0.8085195422172546,
        "meteor": 0.0,
        "sbert_similarity": -0.0034282305277884007
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie go on another roadtrip soon?",
      "prediction": "No, based on the given context, Melanie does not seem to have mentioned plans for another road trip.",
      "reference": "Likely no; since this one went badly",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.08,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08,
        "bleu1": 0.047619047619047616,
        "bleu2": 0.01543033499620919,
        "bleu3": 0.011280777824436245,
        "bleu4": 0.00913442366656447,
        "bert_precision": 0.8503674864768982,
        "bert_recall": 0.8422173261642456,
        "bert_f1": 0.8462727665901184,
        "meteor": 0.0,
        "sbert_similarity": 0.2741728723049164
      }
    },
    {
      "sample_id": 0,
      "question": "What items has Melanie bought?",
      "prediction": "None of Melanie's purchases are mentioned directly in the provided context.",
      "reference": "Figurines, shoes",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8395119905471802,
        "bert_recall": 0.769542396068573,
        "bert_f1": 0.8030059337615967,
        "meteor": 0.0,
        "sbert_similarity": 0.19492794573307037
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline pass the adoption interview?",
      "prediction": "22-10-2023",
      "reference": "The Friday before 22 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8295948505401611,
        "bert_recall": 0.8098823428153992,
        "bert_f1": 0.8196200728416443,
        "meteor": 0.0,
        "sbert_similarity": 0.5559473037719727
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie buy the figurines?",
      "prediction": "DATE OF CONVERSATION: 22 October, 2023",
      "reference": "21 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.28571428571428575,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.25,
        "bleu2": 0.059761430466719695,
        "bleu3": 0.04033183084278514,
        "bleu4": 0.03303164318013808,
        "bert_precision": 0.8544819951057434,
        "bert_recall": 0.9292095303535461,
        "bert_f1": 0.8902804255485535,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.7091982364654541
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline want to move back to her home country soon?",
      "prediction": "No, Caroline does not seem to want to move back soon based on the provided context.",
      "reference": "No; she's in the process of adopting children.",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.08695652173913045,
        "rouge1_f": 0.16,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.03131121455425748,
        "bleu3": 0.019045937245652737,
        "bleu4": 0.014216645907653848,
        "bert_precision": 0.8637613654136658,
        "bert_recall": 0.8882001042366028,
        "bert_f1": 0.8758103251457214,
        "meteor": 0.056818181818181816,
        "sbert_similarity": 0.3121369481086731
      }
    },
    {
      "sample_id": 0,
      "question": "What did the charity race raise awareness for?",
      "prediction": "No information provided about a charity race or the cause it raised awareness for.",
      "reference": "mental health",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8076416254043579,
        "bert_recall": 0.8302513957023621,
        "bert_f1": 0.8187904953956604,
        "meteor": 0.0,
        "sbert_similarity": 0.09895758330821991
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie realize after the charity race?",
      "prediction": "That charity race sounds great, Mel! Making a difference & raising awareness for mental health is super rewarding - I'm really proud of you for taking part!",
      "reference": "self-care is important",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.06896551724137931,
        "rouge1_f": 0.06666666666666668,
        "rouge2_f": 0.0,
        "rougeL_f": 0.06666666666666668,
        "bleu1": 0.03225806451612903,
        "bleu2": 0.010369516947304258,
        "bleu3": 0.007547607157773618,
        "bleu4": 0.006032401726201458,
        "bert_precision": 0.8153451681137085,
        "bert_recall": 0.8694783449172974,
        "bert_f1": 0.8415420651435852,
        "meteor": 0.0925925925925926,
        "sbert_similarity": 0.2244875282049179
      }
    },
    {
      "sample_id": 0,
      "question": "How does Melanie prioritize self-care?",
      "prediction": "Taking care of ourselves is so important - even if it's not always easy.",
      "reference": "by carving out some me-time each day for activities like running, reading, or playing the violin",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8427401185035706,
        "bert_recall": 0.8513004779815674,
        "bert_f1": 0.8469986915588379,
        "meteor": 0.03164556962025316,
        "sbert_similarity": 0.2815392017364502
      }
    },
    {
      "sample_id": 0,
      "question": "What are Caroline's plans for the summer?",
      "prediction": "Right, it was so much fun! We could do a family outing, or wanna plan something special for this summer, just us two? It'd be a great chance to catch up and explore nature!",
      "reference": "researching adoption agencies",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7964412569999695,
        "bert_recall": 0.8419871926307678,
        "bert_f1": 0.8185811638832092,
        "meteor": 0.0,
        "sbert_similarity": 0.05606616660952568
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Caroline is considering support?",
      "prediction": "LGBTQ+ individuals",
      "reference": "LGBTQ+ individuals",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.000000238418579,
        "bert_recall": 1.000000238418579,
        "bert_f1": 1.000000238418579,
        "meteor": 0.9375,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose the adoption agency?",
      "prediction": "To turn her dream of having a family and giving a loving home to kids who need it into reality.",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14814814814814814,
        "rouge1_f": 0.13793103448275865,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13793103448275865,
        "bleu1": 0.09523809523809525,
        "bleu2": 0.02182178902359924,
        "bleu3": 0.0141800886003256,
        "bleu4": 0.010862721615727716,
        "bert_precision": 0.8366737365722656,
        "bert_recall": 0.8246961832046509,
        "bert_f1": 0.8306418061256409,
        "meteor": 0.09900990099009901,
        "sbert_similarity": 0.18355268239974976
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline excited about in the adoption process?",
      "prediction": "Gathering documents like references, financial info and medical checks; preparing emotionally; turning her dream into a reality; researching adoption agencies; finding an adoption agency or lawyer; giving a loving home to kids who need it.",
      "reference": "creating a family for kids who need one",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1951219512195122,
        "rouge1_f": 0.18604651162790695,
        "rouge2_f": 0.0975609756097561,
        "rougeL_f": 0.18604651162790695,
        "bleu1": 0.09523809523809525,
        "bleu2": 0.06815981765909969,
        "bleu3": 0.05028621640566958,
        "bleu4": 0.023360549828121566,
        "bert_precision": 0.8165808916091919,
        "bert_recall": 0.881569504737854,
        "bert_f1": 0.847831666469574,
        "meteor": 0.35046728971962615,
        "sbert_similarity": 0.42936623096466064
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie think about Caroline's decision to adopt?",
      "prediction": "Wow, Caroline! That's huge! How did it feel to be around so much love and acceptance?",
      "reference": "she thinks Caroline is doing something amazing and will be an awesome mom",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.20689655172413793,
        "rouge1_f": 0.20000000000000004,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.026726124191242442,
        "bleu3": 0.016210225632977325,
        "bleu4": 0.012021577610863726,
        "bert_precision": 0.8499816060066223,
        "bert_recall": 0.8674754500389099,
        "bert_f1": 0.8586394190788269,
        "meteor": 0.11278195488721804,
        "sbert_similarity": 0.5310038924217224
      }
    },
    {
      "sample_id": 0,
      "question": "How long have Mel and her husband been married?",
      "prediction": "Wow, what an amazing family pic! How long have you been married?",
      "reference": "Mel and her husband have been married for 5 years.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2727272727272727,
        "rouge1_f": 0.2727272727272727,
        "rouge2_f": 0.09999999999999999,
        "rougeL_f": 0.2727272727272727,
        "bleu1": 0.2,
        "bleu2": 0.11952286093343935,
        "bleu3": 0.04937604958709526,
        "bleu4": 0.030934588294313718,
        "bert_precision": 0.8636370897293091,
        "bert_recall": 0.8866586685180664,
        "bert_f1": 0.8749964833259583,
        "meteor": 0.09803921568627452,
        "sbert_similarity": 0.32091647386550903
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's necklace symbolize?",
      "prediction": "Love, faith, and strength",
      "reference": "love, faith, and strength",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.9998108148574829,
        "bert_recall": 0.9998108148574829,
        "bert_f1": 0.9998108148574829,
        "meteor": 0.9921875,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Caroline's grandma from?",
      "prediction": "{}\n{\"answer\":\"US\"}",
      "reference": "Sweden",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.772576093673706,
        "bert_recall": 0.9073703289031982,
        "bert_f1": 0.8345654606819153,
        "meteor": 0.0,
        "sbert_similarity": 0.21224024891853333
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Caroline?",
      "prediction": "A necklace",
      "reference": "necklace",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.8517659902572632,
        "bert_recall": 0.9151227474212646,
        "bert_f1": 0.8823084831237793,
        "meteor": 0.45454545454545453,
        "sbert_similarity": 0.9594278931617737
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's hand-painted bowl a reminder of?",
      "prediction": "A friend made it for her 18th birthday ten years ago.",
      "reference": "art and self-expression",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.826572060585022,
        "bert_recall": 0.8635863661766052,
        "bert_f1": 0.8446739315986633,
        "meteor": 0.0,
        "sbert_similarity": 0.21190029382705688
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family do while camping?",
      "prediction": "We explored nature, roasted marshmallows around the campfire and even went on a hike.",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.782608695652174,
        "rouge1_f": 0.782608695652174,
        "rouge2_f": 0.5714285714285714,
        "rougeL_f": 0.782608695652174,
        "bleu1": 0.625,
        "bleu2": 0.5400617248673217,
        "bleu3": 0.4740787544325408,
        "bleu4": 0.393755531055134,
        "bert_precision": 0.9372093677520752,
        "bert_recall": 0.9644695520401001,
        "bert_f1": 0.9506440758705139,
        "meteor": 0.7078410311493017,
        "sbert_similarity": 0.8735734224319458
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Caroline interested in pursuing?",
      "prediction": "Counseling or working in mental health",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3157894736842105,
        "rouge1_f": 0.3157894736842105,
        "rouge2_f": 0.11764705882352941,
        "rougeL_f": 0.3157894736842105,
        "bleu1": 0.13179856905786336,
        "bleu2": 0.08335673411476816,
        "bleu3": 0.03649731313368611,
        "bleu4": 0.025185198565837008,
        "bert_precision": 0.8373327255249023,
        "bert_recall": 0.8344811201095581,
        "bert_f1": 0.8359044790267944,
        "meteor": 0.20776874435411022,
        "sbert_similarity": 0.5704362392425537
      }
    },
    {
      "sample_id": 0,
      "question": "What workshop did Caroline attend recently?",
      "prediction": "No workshop is mentioned recently for Caroline.",
      "reference": "LGBTQ+ counseling workshop",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.04225771273642583,
        "bleu3": 0.032085442892067474,
        "bleu4": 0.02777619034011792,
        "bert_precision": 0.8834055066108704,
        "bert_recall": 0.8485967516899109,
        "bert_f1": 0.8656513690948486,
        "meteor": 0.14705882352941177,
        "sbert_similarity": 0.30459967255592346
      }
    },
    {
      "sample_id": 0,
      "question": "What was discussed in the LGBTQ+ counseling workshop?",
      "prediction": "Different therapeutic methods and how to best work with trans people.",
      "reference": "therapeutic methods and how to best work with trans people",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.9523809523809523,
        "rouge1_f": 0.9523809523809523,
        "rouge2_f": 0.9473684210526316,
        "rougeL_f": 0.9523809523809523,
        "bleu1": 0.8333333333333334,
        "bleu2": 0.8257228238447705,
        "bleu3": 0.8187104363805253,
        "bleu4": 0.8070557274927982,
        "bert_precision": 0.9778479337692261,
        "bert_recall": 0.9872344136238098,
        "bert_f1": 0.98251873254776,
        "meteor": 0.8904779366825571,
        "sbert_similarity": 0.9825106859207153
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Caroline to pursue counseling?",
      "prediction": "Lately, I've been looking into counseling and mental health as a career. I want to help people who have gone through the same things as me.",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16216216216216217,
        "rouge1_f": 0.14634146341463417,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0975609756097561,
        "bleu1": 0.13333333333333333,
        "bleu2": 0.021442250696755896,
        "bleu3": 0.012333214743941176,
        "bleu4": 0.008830895300928163,
        "bert_precision": 0.8661861419677734,
        "bert_recall": 0.8720176219940186,
        "bert_f1": 0.8690921068191528,
        "meteor": 0.13157894736842107,
        "sbert_similarity": 0.5007754564285278
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Caroline want to create for people?",
      "prediction": "a safe and loving home",
      "reference": "a safe and inviting place for people to grow",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.42857142857142855,
        "rouge1_f": 0.42857142857142855,
        "rouge2_f": 0.3333333333333333,
        "rougeL_f": 0.42857142857142855,
        "bleu1": 0.26959737847033294,
        "bleu2": 0.24610760938743165,
        "bleu3": 0.21016694651579904,
        "bleu4": 0.11948321931215808,
        "bert_precision": 0.9225906133651733,
        "bert_recall": 0.8910180926322937,
        "bert_f1": 0.9065295457839966,
        "meteor": 0.436046511627907,
        "sbert_similarity": 0.556976318359375
      }
    },
    {
      "sample_id": 0,
      "question": "Did Melanie make the black and white bowl in the photo?",
      "prediction": "That bowl is gorgeous! The black and white design looks so fancy. Did you make it?",
      "reference": "Yes",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.790020763874054,
        "bert_recall": 0.8280439972877502,
        "bert_f1": 0.8085855841636658,
        "meteor": 0.0,
        "sbert_similarity": 0.11332511156797409
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of books does Caroline have in her library?",
      "prediction": "Caroline has kids' books- classics, stories from different cultures, educational books, all of that.",
      "reference": "kids' books - classics, stories from different cultures, educational books",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6956521739130435,
        "rouge1_f": 0.782608695652174,
        "rouge2_f": 0.761904761904762,
        "rougeL_f": 0.782608695652174,
        "bleu1": 0.5789473684210527,
        "bleu2": 0.5380275868489703,
        "bleu3": 0.4956386990444981,
        "bleu4": 0.4598036015897535,
        "bert_precision": 0.9294300079345703,
        "bert_recall": 0.9506151080131531,
        "bert_f1": 0.9399031400680542,
        "meteor": 0.6652276295133438,
        "sbert_similarity": 0.6960523128509521
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's favorite book from her childhood?",
      "prediction": "That was \"Charlotte's Web\" from her childhood.",
      "reference": "\"Charlotte's Web\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444445,
        "rouge1_f": 0.5454545454545454,
        "rouge2_f": 0.4444444444444445,
        "rougeL_f": 0.5454545454545454,
        "bleu1": 0.45454545454545453,
        "bleu2": 0.4264014327112209,
        "bleu3": 0.3964882289652318,
        "bleu4": 0.3508439695638686,
        "bert_precision": 0.8900962471961975,
        "bert_recall": 0.9350458383560181,
        "bert_f1": 0.9120175242424011,
        "meteor": 0.75,
        "sbert_similarity": 0.8274543285369873
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Caroline recommend to Melanie?",
      "prediction": "\"that book you recommended a while ago\"",
      "reference": "\"Becoming Nicole\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.2222222222222222,
        "bleu2": 0.05270462766947299,
        "bleu3": 0.03528075103412339,
        "bleu4": 0.028517539529041507,
        "bert_precision": 0.8382440209388733,
        "bert_recall": 0.8651770353317261,
        "bert_f1": 0.8514975905418396,
        "meteor": 0.0,
        "sbert_similarity": 0.14059798419475555
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline take away from the book \"Becoming Nicole\"?",
      "prediction": "It made Caroline feel connected and gave her a lot of hope for her own path.",
      "reference": "Lessons on self-acceptance and finding support",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809522,
        "rouge1_f": 0.08695652173913043,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08695652173913043,
        "bleu1": 0.0588235294117647,
        "bleu2": 0.019174124721184262,
        "bleu3": 0.014076093604378503,
        "bleu4": 0.011502783619900045,
        "bert_precision": 0.8681219816207886,
        "bert_recall": 0.8646447658538818,
        "bert_f1": 0.8663799166679382,
        "meteor": 0.14285714285714288,
        "sbert_similarity": 0.14045657217502594
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Melanie got used for?",
      "prediction": "new shoes used for a photo shoot or as a fashion accessory, based on the context provided. However, the exact usage is not specified.",
      "reference": "Running",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.797480046749115,
        "bert_recall": 0.8397601842880249,
        "bert_f1": 0.8180742263793945,
        "meteor": 0.0,
        "sbert_similarity": 0.10412462055683136
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's reason for getting into running?",
      "prediction": "Running can really boost your mood.",
      "reference": "To de-stress and clear her mind",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8941391706466675,
        "bert_recall": 0.8921612501144409,
        "bert_f1": 0.8931491374969482,
        "meteor": 0.0,
        "sbert_similarity": 0.2972654402256012
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie say running has been great for?",
      "prediction": "running has been great for her headspace.",
      "reference": "Her mental health",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.04225771273642583,
        "bleu3": 0.032085442892067474,
        "bleu4": 0.02777619034011792,
        "bert_precision": 0.8505576848983765,
        "bert_recall": 0.8503251075744629,
        "bert_f1": 0.8504413962364197,
        "meteor": 0.14705882352941177,
        "sbert_similarity": 0.3802279531955719
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids make during the pottery workshop?",
      "prediction": "Mel and her kids made clay pots during the pottery workshop.",
      "reference": "pots",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666669,
        "rouge1_f": 0.16666666666666669,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666669,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.027524094128159027,
        "bleu3": 0.020427282860665447,
        "bleu4": 0.017033186037639283,
        "bert_precision": 0.8095608949661255,
        "bert_recall": 0.8474521636962891,
        "bert_f1": 0.828073263168335,
        "meteor": 0.25000000000000006,
        "sbert_similarity": 0.46856409311294556
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of pot did Mel and her kids make with clay?",
      "prediction": "Speaker Mel says they made their own pots with clay.",
      "reference": "a cup with a dog face on it",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352941,
        "rouge1_f": 0.11111111111111112,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11111111111111112,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.03015113445777637,
        "bleu3": 0.022461584318318094,
        "bleu4": 0.018850319022747353,
        "bert_precision": 0.862015962600708,
        "bert_recall": 0.8526977300643921,
        "bert_f1": 0.8573315143585205,
        "meteor": 0.06097560975609756,
        "sbert_similarity": 0.037292394787073135
      }
    },
    {
      "sample_id": 0,
      "question": "What creative project do Mel and her kids do together besides pottery?",
      "prediction": "pottery workshop",
      "reference": "painting",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8067371845245361,
        "bert_recall": 0.8735080361366272,
        "bert_f1": 0.8387959599494934,
        "meteor": 0.0,
        "sbert_similarity": 0.43824973702430725
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids paint in their latest project in July 2023?",
      "prediction": "That information is not provided in the given context.",
      "reference": "a sunset with a palm tree",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.841914713382721,
        "bert_recall": 0.8648507595062256,
        "bert_f1": 0.8532286286354065,
        "meteor": 0.0,
        "sbert_similarity": -0.03339630737900734
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline see at the council meeting for adoption?",
      "prediction": "That she saw an inspiring and emotional scene where many people wanted to create loving homes for children in need.",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6451612903225806,
        "rouge1_f": 0.7096774193548387,
        "rouge2_f": 0.6896551724137931,
        "rougeL_f": 0.7096774193548387,
        "bleu1": 0.47619047619047616,
        "bleu2": 0.4364357804719848,
        "bleu3": 0.39550197284418853,
        "bleu4": 0.35952902857522767,
        "bert_precision": 0.9042741060256958,
        "bert_recall": 0.9535812735557556,
        "bert_f1": 0.9282734394073486,
        "meteor": 0.8399159663865546,
        "sbert_similarity": 0.6592897772789001
      }
    },
    {
      "sample_id": 0,
      "question": "What do sunflowers represent according to Caroline?",
      "prediction": "Blue's my fave, it makes me feel relaxed.\nSunflowers mean warmth and happiness, right?",
      "reference": "warmth and happiness",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.35294117647058826,
        "rouge1_f": 0.33333333333333337,
        "rouge2_f": 0.25,
        "rougeL_f": 0.33333333333333337,
        "bleu1": 0.15789473684210523,
        "bleu2": 0.13245323570650439,
        "bleu3": 0.10339824169628065,
        "bleu4": 0.05039518688486959,
        "bert_precision": 0.8384068012237549,
        "bert_recall": 0.8858529329299927,
        "bert_f1": 0.8614770770072937,
        "meteor": 0.4573170731707317,
        "sbert_similarity": 0.4143984019756317
      }
    },
    {
      "sample_id": 0,
      "question": "Why are flowers important to Melanie?",
      "prediction": "Flowers bring joy, represent growth, beauty, and remind her of small moments, as they were an important part of her wedding decor.",
      "reference": "They remind her to appreciate the small moments and were a part of her wedding decor",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6285714285714286,
        "rouge1_f": 0.631578947368421,
        "rouge2_f": 0.3333333333333333,
        "rougeL_f": 0.5263157894736842,
        "bleu1": 0.4444444444444444,
        "bleu2": 0.3202563076101743,
        "bleu3": 0.23429244686826672,
        "bleu4": 0.17895706401541522,
        "bert_precision": 0.8962893486022949,
        "bert_recall": 0.9177840948104858,
        "bert_f1": 0.9069094061851501,
        "meteor": 0.6157965194109771,
        "sbert_similarity": 0.7503877878189087
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's painting for the art show?",
      "prediction": "Seeing how art can be a source of self-expression and growth is truly inspiring. Your creativity really shines.",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.07142857142857142,
        "rouge1_f": 0.06666666666666667,
        "rouge2_f": 0.0,
        "rougeL_f": 0.06666666666666667,
        "bleu1": 0.05000000000000001,
        "bleu2": 0.01622214211307625,
        "bleu3": 0.01186947435439869,
        "bleu4": 0.009629943614188135,
        "bert_precision": 0.8679555654525757,
        "bert_recall": 0.8513087630271912,
        "bert_f1": 0.8595515489578247,
        "meteor": 0.08547008547008547,
        "sbert_similarity": 0.1894633024930954
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Melanie go to the beach with her kids?",
      "prediction": "usually only once or twice a year",
      "reference": "once or twice a year",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8333333333333333,
        "rouge1_f": 0.8333333333333333,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8333333333333333,
        "bleu1": 0.7142857142857143,
        "bleu2": 0.6900655593423543,
        "bleu3": 0.6613898798842307,
        "bleu4": 0.6147881529512643,
        "bert_precision": 0.9254478216171265,
        "bert_recall": 0.9496265649795532,
        "bert_f1": 0.9373813271522522,
        "meteor": 0.9576923076923077,
        "sbert_similarity": 0.915164053440094
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family see during their camping trip last year?",
      "prediction": "The Perseid meteor shower",
      "reference": "Perseid meteor shower",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8571428571428571,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.75,
        "bleu2": 0.7071067811865475,
        "bleu3": 0.63287829698514,
        "bleu4": 0.3976353643835253,
        "bert_precision": 0.909468412399292,
        "bert_recall": 0.9297232627868652,
        "bert_f1": 0.9194843173027039,
        "meteor": 0.9498207885304659,
        "sbert_similarity": 0.9688671231269836
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel while watching the meteor shower?",
      "prediction": "The sky was so clear and filled with stars, and the meteor shower was amazing - it felt like we were part of something huge and awe-inspiring.",
      "reference": "in awe of the universe",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714285,
        "rouge1_f": 0.18750000000000003,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0625,
        "bleu1": 0.06896551724137931,
        "bleu2": 0.01569412051435861,
        "bleu3": 0.0101586586333325,
        "bleu4": 0.007696339439306161,
        "bert_precision": 0.8289888501167297,
        "bert_recall": 0.8751678466796875,
        "bert_f1": 0.8514527082443237,
        "meteor": 0.1388888888888889,
        "sbert_similarity": 0.40577152371406555
      }
    },
    {
      "sample_id": 0,
      "question": "Whose birthday did Melanie celebrate recently?",
      "prediction": "Melanie's daughter's birthday",
      "reference": "Melanie's daughter",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.7499999999999999,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.7499999999999999,
        "bleu1": 0.6,
        "bleu2": 0.5477225575051662,
        "bleu3": 0.4677351412871982,
        "bleu4": 0.26591479484724945,
        "bert_precision": 0.9151952266693115,
        "bert_recall": 0.9586464166641235,
        "bert_f1": 0.9364170432090759,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.8563249111175537
      }
    },
    {
      "sample_id": 0,
      "question": "Who performed at the concert at Melanie's daughter's birthday?",
      "prediction": "The context does not specify who performed at the concert.",
      "reference": "Matt Patterson",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8391083478927612,
        "bert_recall": 0.812487006187439,
        "bert_f1": 0.8255831003189087,
        "meteor": 0.0,
        "sbert_similarity": 0.06739755719900131
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose to use colors and patterns in her pottery project?",
      "prediction": "It's not explicitly stated, but Melanie appreciates the creativity and skill in pottery and finds it calming, as expressed in her posts. Her response to Carolines suggests she loves the \"pattern and colors\" in her hand-painted bowl, indicating she enjoys incorporating these elements into her pottery.",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1739130434782609,
        "rouge1_f": 0.13793103448275862,
        "rouge2_f": 0.0,
        "rougeL_f": 0.10344827586206896,
        "bleu1": 0.09259259259259259,
        "bleu2": 0.013217526428635742,
        "bleu3": 0.007305972283762186,
        "bleu4": 0.00506619280504146,
        "bert_precision": 0.8343790769577026,
        "bert_recall": 0.8848307728767395,
        "bert_f1": 0.8588646054267883,
        "meteor": 0.14705882352941177,
        "sbert_similarity": 0.24827176332473755
      }
    },
    {
      "sample_id": 0,
      "question": "What pet does Caroline have?",
      "prediction": "None of the conversations mention Caroline having a pet.",
      "reference": "guinea pig",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8421391844749451,
        "bert_recall": 0.7796850800514221,
        "bert_f1": 0.8097096085548401,
        "meteor": 0.0,
        "sbert_similarity": 0.14374589920043945
      }
    },
    {
      "sample_id": 0,
      "question": "What pets does Melanie have?",
      "prediction": "[Image: a photo of a cat laying on the floor with its head on the floor]\nPup and a kitty.",
      "reference": "Two cats and a dog",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.19047619047619047,
        "rouge1_f": 0.24,
        "rouge2_f": 0.08695652173913043,
        "rougeL_f": 0.24,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.06019292654288461,
        "bleu3": 0.026393714719473722,
        "bleu4": 0.016734480530603443,
        "bert_precision": 0.8272459506988525,
        "bert_recall": 0.87320876121521,
        "bert_f1": 0.8496061563491821,
        "meteor": 0.39316239316239315,
        "sbert_similarity": 0.6269513368606567
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oliver hide his bone once?",
      "prediction": "None of the provided context mentions a character named Oliver or a bone being hidden.",
      "reference": "In Melanie's slipper",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8201209306716919,
        "bert_recall": 0.8238839507102966,
        "bert_f1": 0.821998119354248,
        "meteor": 0.0,
        "sbert_similarity": 0.164957195520401
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Caroline used to do with her dad?",
      "prediction": "There is no information provided about Caroline doing activities with her dad.",
      "reference": "Horseback riding",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8280283212661743,
        "bert_recall": 0.7679780721664429,
        "bert_f1": 0.7968735098838806,
        "meteor": 0.0,
        "sbert_similarity": 0.02582857944071293
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline make for a local church?",
      "prediction": "a stained glass window",
      "reference": "a stained glass window",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9921875,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline find in her neighborhood during her walk?",
      "prediction": "No relevant information provided in the context for this question.",
      "reference": "a rainbow sidewalk",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8093879222869873,
        "bert_recall": 0.8465134501457214,
        "bert_f1": 0.8275344967842102,
        "meteor": 0.0,
        "sbert_similarity": -0.006143903359770775
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Caroline to be courageous?",
      "prediction": "\"Cool\" by Sara Bareilles",
      "reference": "Brave by Sara Bareilles",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.75,
        "rouge1_f": 0.75,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.75,
        "bleu1": 0.5,
        "bleu2": 0.447213595499958,
        "bleu3": 0.3721003696282278,
        "bleu4": 0.20205155046766235,
        "bert_precision": 0.9051188826560974,
        "bert_recall": 0.9463179111480713,
        "bert_f1": 0.9252599477767944,
        "meteor": 0.7361111111111112,
        "sbert_similarity": 0.7213602662086487
      }
    },
    {
      "sample_id": 0,
      "question": "Which  classical musicians does Melanie enjoy listening to?",
      "prediction": "[\"Melaniesays : I'm a fan of both classical like Bach and Mozart\"]",
      "reference": "Bach and Mozart",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.26666666666666666,
        "rouge1_f": 0.4,
        "rouge2_f": 0.3076923076923077,
        "rougeL_f": 0.4,
        "bleu1": 0.17647058823529413,
        "bleu2": 0.14852213144650114,
        "bleu3": 0.11621764179681902,
        "bleu4": 0.05692994482485313,
        "bert_precision": 0.8181168437004089,
        "bert_recall": 0.8910075426101685,
        "bert_f1": 0.8530079126358032,
        "meteor": 0.48076923076923084,
        "sbert_similarity": 0.7207745909690857
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Melanie a fan of in terms of modern music?",
      "prediction": "Caroline",
      "reference": "Ed Sheeran",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8876967430114746,
        "bert_recall": 0.7209846377372742,
        "bert_f1": 0.7957022786140442,
        "meteor": 0.0,
        "sbert_similarity": 0.18620462715625763
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been creating art?",
      "prediction": "How long has Melanie been creating art? memory context: Speaker Melaniesays : Thanks, Caroline! Painting's a fun way to express my feelings and get creative. It's a great way to relax after a long day. memory tags: []",
      "reference": "7 years",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7892767190933228,
        "bert_recall": 0.8354798555374146,
        "bert_f1": 0.8117213249206543,
        "meteor": 0.0,
        "sbert_similarity": 0.28453508019447327
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Melanie see at the caf\u00e9?",
      "prediction": "[a photo of a sign posted on a door stating that someone is not being able to leave]",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7142857142857143,
        "rouge1_f": 0.7586206896551725,
        "rouge2_f": 0.6666666666666667,
        "rougeL_f": 0.7586206896551725,
        "bleu1": 0.55,
        "bleu2": 0.5104177855340404,
        "bleu3": 0.46975720926993464,
        "bleu4": 0.4348553979929487,
        "bert_precision": 0.9099827408790588,
        "bert_recall": 0.9527972340583801,
        "bert_f1": 0.9308979511260986,
        "meteor": 0.8431623931623934,
        "sbert_similarity": 0.7845034599304199
      }
    },
    {
      "sample_id": 0,
      "question": "What advice does Caroline give for getting started with adoption?",
      "prediction": "Do your research and find an adoption agency or lawyer. They'll help with the process and provide all the info. Gather documents like references, financial info and medical checks. Don't forget to prepare emotionally, since the wait can be hard.",
      "reference": "Do research, find an adoption agency or lawyer, gather necessary documents, and prepare emotionally.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5306122448979592,
        "rouge1_f": 0.46428571428571436,
        "rouge2_f": 0.2222222222222222,
        "rougeL_f": 0.46428571428571436,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.2062842492517587,
        "bleu3": 0.15758588611896324,
        "bleu4": 0.12532443621763048,
        "bert_precision": 0.8881880044937134,
        "bert_recall": 0.9453722238540649,
        "bert_f1": 0.9158884286880493,
        "meteor": 0.49568644950171065,
        "sbert_similarity": 0.8916807174682617
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Melanie face in October 2023?",
      "prediction": "There is no mention of any setback faced by Melanie in October 2023 in the provided context.",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.05555555555555554,
        "bleu2": 0.018077538151554672,
        "bleu3": 0.013254163846385744,
        "bleu4": 0.010802314890908065,
        "bert_precision": 0.857802152633667,
        "bert_recall": 0.8704497814178467,
        "bert_f1": 0.8640797138214111,
        "meteor": 0.0,
        "sbert_similarity": 0.24341246485710144
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to keep herself busy during her pottery break?",
      "prediction": "Melanie took her kids to a pottery workshop.",
      "reference": "Read a book and paint.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.15384615384615385,
        "rouge1_f": 0.15384615384615385,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615385,
        "bleu1": 0.2222222222222222,
        "bleu2": 0.05270462766947299,
        "bleu3": 0.03528075103412339,
        "bleu4": 0.028517539529041507,
        "bert_precision": 0.8711822628974915,
        "bert_recall": 0.8772447109222412,
        "bert_f1": 0.8742030262947083,
        "meteor": 0.18867924528301888,
        "sbert_similarity": 0.14638501405715942
      }
    },
    {
      "sample_id": 0,
      "question": "What painting did Melanie show to Caroline on October 13, 2023?",
      "prediction": "[a photo of a painting of a sunset with a pink sky]",
      "reference": "A painting inspired by sunsets with a pink sky.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.47058823529411764,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5263157894736842,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.36313651960128146,
        "bleu3": 0.2836979771131725,
        "bleu4": 0.21142141714303078,
        "bert_precision": 0.9151628613471985,
        "bert_recall": 0.9312224388122559,
        "bert_f1": 0.9231228232383728,
        "meteor": 0.6048387096774195,
        "sbert_similarity": 0.8950473666191101
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of painting did Caroline share with Melanie on October 13, 2023?",
      "prediction": "a painting of a sunset with a pink sky",
      "reference": "An abstract painting with blue streaks on a wall.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.375,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.2982797722714565,
        "bleu2": 0.057761629525894614,
        "bleu3": 0.03609050795723058,
        "bleu4": 0.028240990488565418,
        "bert_precision": 0.9109269976615906,
        "bert_recall": 0.9126874208450317,
        "bert_f1": 0.9118064045906067,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.5040774345397949
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Caroline attended about?",
      "prediction": "It was really powerful.",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.26666666666666666,
        "rouge1_f": 0.25,
        "rouge2_f": 0.14285714285714288,
        "rougeL_f": 0.25,
        "bleu1": 0.12113791079679323,
        "bleu2": 0.07819418518505664,
        "bleu3": 0.03513896216464457,
        "bleu4": 0.0253871431063062,
        "bert_precision": 0.9076462388038635,
        "bert_recall": 0.8546125292778015,
        "bert_f1": 0.8803313970565796,
        "meteor": 0.16741071428571427,
        "sbert_similarity": 0.1300111562013626
      }
    },
    {
      "sample_id": 0,
      "question": "What did the posters at the poetry reading say?",
      "prediction": "The posters were amazing, so much pride and strength!",
      "reference": "\"Trans Lives Matter\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8237501382827759,
        "bert_recall": 0.8320396542549133,
        "bert_f1": 0.8278741240501404,
        "meteor": 0.13888888888888892,
        "sbert_similarity": 0.0876564010977745
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's drawing symbolize for her?",
      "prediction": "freedom and being real",
      "reference": "Freedom and being true to herself.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6,
        "rouge1_f": 0.6,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6,
        "bleu1": 0.354274914555761,
        "bleu2": 0.3340135926488844,
        "bleu3": 0.2989505394514747,
        "bleu4": 0.1878296463217631,
        "bert_precision": 0.9402900338172913,
        "bert_recall": 0.9208530187606812,
        "bert_f1": 0.9304699897766113,
        "meteor": 0.5076628352490421,
        "sbert_similarity": 0.6762146949768066
      }
    },
    {
      "sample_id": 0,
      "question": "How do Melanie and Caroline describe their journey through life together?",
      "prediction": "All those moments together as a family are special, life's about learning and exploring, and music and books guide and inspire us.",
      "reference": "An ongoing adventure of learning and growing.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.15384615384615385,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.07142857142857144,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.1153846153846154,
        "bleu2": 0.06793662204867576,
        "bleu3": 0.02777914640205232,
        "bleu4": 0.01700463072175106,
        "bert_precision": 0.8587703704833984,
        "bert_recall": 0.8924894332885742,
        "bert_f1": 0.8753052949905396,
        "meteor": 0.11764705882352941,
        "sbert_similarity": 0.34938713908195496
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Melanie's son on their road trip?",
      "prediction": "No relevant information found in the provided context for the question \"What happened to Melanie's son on their road trip? \".",
      "reference": "He got into an accident",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8349108695983887,
        "bert_recall": 0.8745612502098083,
        "bert_f1": 0.854276180267334,
        "meteor": 0.0,
        "sbert_similarity": 0.36371392011642456
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's son handle the accident?",
      "prediction": "The context does not provide specific details on how Melanie's son handled the accident; it only mentions that \"Thankfully, my son's ok\" and that it was a \"reminder that life is precious and to cherish our family.\"",
      "reference": "He was scared but reassured by his family",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0975609756097561,
        "rouge1_f": 0.0851063829787234,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0851063829787234,
        "bleu1": 0.043478260869565216,
        "bleu2": 0.009829463743659813,
        "bleu3": 0.0063493651119262825,
        "bleu4": 0.004753731294736233,
        "bert_precision": 0.823978066444397,
        "bert_recall": 0.8602648973464966,
        "bert_f1": 0.8417305946350098,
        "meteor": 0.045871559633027525,
        "sbert_similarity": 0.3356800377368927
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family after the accident?",
      "prediction": "They mean the world to me and I'm so thankful to have them.",
      "reference": "They are important and mean the world to her",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5217391304347826,
        "rouge2_f": 0.2857142857142857,
        "rougeL_f": 0.43478260869565216,
        "bleu1": 0.4,
        "bleu2": 0.29277002188455997,
        "bleu3": 0.23968792281200063,
        "bleu4": 0.18207052811092134,
        "bert_precision": 0.9114429950714111,
        "bert_recall": 0.9386459589004517,
        "bert_f1": 0.92484450340271,
        "meteor": 0.5437352245862884,
        "sbert_similarity": 0.4780944287776947
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's children handle the accident?",
      "prediction": "They were scared but were reassured and explained their brother would be okay.",
      "reference": "They were scared but resilient",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.47058823529411764,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.375,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.25677629550654774,
        "bleu3": 0.22569209116099667,
        "bleu4": 0.1777835117834348,
        "bert_precision": 0.8809657096862793,
        "bert_recall": 0.9208100438117981,
        "bert_f1": 0.9004473090171814,
        "meteor": 0.5441810344827587,
        "sbert_similarity": 0.5945043563842773
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel after the accident?",
      "prediction": "Melanie felt scared during the accident and grateful that her son was okay.",
      "reference": "Grateful and thankful for her family",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3157894736842105,
        "rouge1_f": 0.3157894736842105,
        "rouge2_f": 0.0,
        "rougeL_f": 0.21052631578947367,
        "bleu1": 0.21428571428571425,
        "bleu2": 0.040599897147057515,
        "bleu3": 0.024859743585800658,
        "bleu4": 0.018798317647335087,
        "bert_precision": 0.8800950646400452,
        "bert_recall": 0.8879424929618835,
        "bert_f1": 0.8840013742446899,
        "meteor": 0.2238805970149254,
        "sbert_similarity": 0.41667211055755615
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's reaction to her children enjoying the Grand Canyon?",
      "prediction": "We do not have any information about Melanie's reaction to her children enjoying the Grand Canyon in the provided context.",
      "reference": "She was happy and thankful",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.831489622592926,
        "bert_recall": 0.8577977418899536,
        "bert_f1": 0.8444387912750244,
        "meteor": 0.0,
        "sbert_similarity": 0.25193265080451965
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's family give her?",
      "prediction": "A photo of a couple of wooden dolls",
      "reference": "Strength and motivation",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8367046117782593,
        "bert_recall": 0.8403722643852234,
        "bert_f1": 0.8385344743728638,
        "meteor": 0.0,
        "sbert_similarity": -0.01912527158856392
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family supporting her?",
      "prediction": "That's awesome, Melanie! How have your family been supportive during your move?",
      "reference": "She appreciated them a lot",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8263813257217407,
        "bert_recall": 0.8564117550849915,
        "bert_f1": 0.8411285281181335,
        "meteor": 0.0,
        "sbert_similarity": 0.30578240752220154
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie do after the road trip to relax?",
      "prediction": "We just did it yesterday! The kids loved it and it was a nice way to relax after the road trip.",
      "reference": "Went on a nature walk or hike",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.08,
        "rouge1_f": 0.07142857142857142,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07142857142857142,
        "bleu1": 0.043478260869565216,
        "bleu2": 0.014058038927888336,
        "bleu3": 0.010263558503321437,
        "bleu4": 0.008282282660969604,
        "bert_precision": 0.8378822803497314,
        "bert_recall": 0.8354578614234924,
        "bert_f1": 0.8366683721542358,
        "meteor": 0.059523809523809514,
        "sbert_similarity": 0.40473389625549316
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline realize after her charity race?",
      "prediction": "Not mentioned in the conversation",
      "reference": "self-care is important",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.877884566783905,
        "bert_recall": 0.876802921295166,
        "bert_f1": 0.8773434162139893,
        "meteor": 0.0,
        "sbert_similarity": 0.10229768604040146
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's plans for the summer with respect to adoption?",
      "prediction": "Not mentioned in the conversation",
      "reference": "researching adoption agencies",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8703113198280334,
        "bert_recall": 0.8672592639923096,
        "bert_f1": 0.868782639503479,
        "meteor": 0.0,
        "sbert_similarity": 0.010256806388497353
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Melanie is considering support?",
      "prediction": "Not mentioned in the conversation",
      "reference": "LGBTQ+ individuals",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.864730179309845,
        "bert_recall": 0.8227474689483643,
        "bert_f1": 0.843216598033905,
        "meteor": 0.0,
        "sbert_similarity": 0.12336073815822601
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose the adoption agency?",
      "prediction": "Not mentioned in the conversation",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.865925669670105,
        "bert_recall": 0.8060603141784668,
        "bert_f1": 0.8349213004112244,
        "meteor": 0.0,
        "sbert_similarity": 0.09916658699512482
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie excited about in her adoption process?",
      "prediction": "Not mentioned in the conversation",
      "reference": "creating a family for kids who need one",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8648307919502258,
        "bert_recall": 0.8169586658477783,
        "bert_f1": 0.840213418006897,
        "meteor": 0.0,
        "sbert_similarity": -0.060942042618989944
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie's necklace symbolize?",
      "prediction": "Not mentioned in the conversation",
      "reference": "love, faith, and strength",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8847731947898865,
        "bert_recall": 0.8560530543327332,
        "bert_f1": 0.8701761960983276,
        "meteor": 0.0,
        "sbert_similarity": 0.04011678695678711
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Melanie's grandma from?",
      "prediction": "Sweden",
      "reference": "Sweden",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 1.000000238418579,
        "bert_recall": 1.000000238418579,
        "bert_f1": 1.000000238418579,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Melanie?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999999403953552,
        "bert_recall": 0.9999999403953552,
        "bert_f1": 0.9999999403953552,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandpa's gift to Caroline?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999999403953552,
        "bert_recall": 0.9999999403953552,
        "bert_f1": 0.9999999403953552,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family do while camping?",
      "prediction": "roasted marshmallows",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363636,
        "rouge1_f": 0.3636363636363636,
        "rouge2_f": 0.2222222222222222,
        "rougeL_f": 0.3636363636363636,
        "bleu1": 0.011108996538242306,
        "bleu2": 0.011108996538242306,
        "bleu3": 0.005196068065373761,
        "bleu4": 0.0035129731579771513,
        "bert_precision": 0.8982498645782471,
        "bert_recall": 0.8472830057144165,
        "bert_f1": 0.8720223903656006,
        "meteor": 0.06024096385542168,
        "sbert_similarity": 0.6268116235733032
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Melanie interested in pursuing?",
      "prediction": "\"Not mentioned in the conversation\"",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.853630006313324,
        "bert_recall": 0.8238161206245422,
        "bert_f1": 0.8384580612182617,
        "meteor": 0.0,
        "sbert_similarity": 0.07238120585680008
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling workshop did Melanie attend recently?",
      "prediction": "Not mentioned in the conversation",
      "reference": "LGBTQ+ counseling workshop",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.880815327167511,
        "bert_recall": 0.822563648223877,
        "bert_f1": 0.8506934642791748,
        "meteor": 0.0,
        "sbert_similarity": 0.11074964702129364
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Melanie to pursue counseling?",
      "prediction": "Not mentioned in the conversation",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352941,
        "rouge1_f": 0.10526315789473682,
        "rouge2_f": 0.0,
        "rougeL_f": 0.10526315789473682,
        "bleu1": 0.027067056647322542,
        "bleu2": 0.009569649651041096,
        "bleu3": 0.007666923387854731,
        "bleu4": 0.007271361304044331,
        "bert_precision": 0.8843756318092346,
        "bert_recall": 0.8464587330818176,
        "bert_f1": 0.8650018572807312,
        "meteor": 0.038167938931297704,
        "sbert_similarity": 0.004239174537360668
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Melanie want to create for people?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a safe and inviting place for people to grow",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8716058135032654,
        "bert_recall": 0.8357222080230713,
        "bert_f1": 0.853286862373352,
        "meteor": 0.0,
        "sbert_similarity": 0.10203901678323746
      }
    },
    {
      "sample_id": 0,
      "question": "Did Caroline make the black and white bowl in the photo?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8480530381202698,
        "bert_recall": 0.8904052376747131,
        "bert_f1": 0.8687132596969604,
        "meteor": 0.0,
        "sbert_similarity": 0.11724156141281128
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Caroline got used for?",
      "prediction": "Running",
      "reference": "Running",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's reason for getting into running?",
      "prediction": "Not mentioned in the conversation",
      "reference": "To de-stress and clear her mind",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8849430084228516,
        "bert_recall": 0.8652691841125488,
        "bert_f1": 0.8749955296516418,
        "meteor": 0.0,
        "sbert_similarity": 0.1525953859090805
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline say running has been great for?",
      "prediction": "Her mental health",
      "reference": "Her mental health",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie see at the council meeting for adoption?",
      "prediction": "Short answer: Many people wanting to create loving homes for children in need",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.9166666666666666,
        "rouge1_f": 0.9166666666666666,
        "rouge2_f": 0.9090909090909091,
        "rougeL_f": 0.9166666666666666,
        "bleu1": 0.7857142857142857,
        "bleu2": 0.7774288420142415,
        "bleu3": 0.7702048427774233,
        "bleu4": 0.7577395672414201,
        "bert_precision": 0.9283012747764587,
        "bert_recall": 0.9589057564735413,
        "bert_f1": 0.9433553218841553,
        "meteor": 0.9817739079102716,
        "sbert_similarity": 0.9523828625679016
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Melanie's painting for the art show?",
      "prediction": "Not mentioned in the conversation",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8672130703926086,
        "bert_recall": 0.8251694440841675,
        "bert_f1": 0.8456690311431885,
        "meteor": 0.0,
        "sbert_similarity": -0.0016056214226409793
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's sculpture for the art show?",
      "prediction": "\"Not mentioned in the conversation\"",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8483411073684692,
        "bert_recall": 0.8290432095527649,
        "bert_f1": 0.8385811448097229,
        "meteor": 0.0,
        "sbert_similarity": -0.025976352393627167
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Caroline go to the beach with her kids?",
      "prediction": "Not mentioned in the conversation",
      "reference": "once or twice a year",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8639419078826904,
        "bert_recall": 0.807560920715332,
        "bert_f1": 0.8348005414009094,
        "meteor": 0.0,
        "sbert_similarity": 0.053056638687849045
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family see during their camping trip last year?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Perseid meteor shower",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8497329354286194,
        "bert_recall": 0.7694872617721558,
        "bert_f1": 0.8076216578483582,
        "meteor": 0.0,
        "sbert_similarity": 0.033341649919748306
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel while watching the meteor shower?",
      "prediction": "Not mentioned in the conversation or in awe of the universe",
      "reference": "in awe of the universe",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7142857142857143,
        "rouge1_f": 0.625,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.625,
        "bleu1": 0.45454545454545453,
        "bleu2": 0.4264014327112209,
        "bleu3": 0.3964882289652318,
        "bleu4": 0.3508439695638686,
        "bert_precision": 0.8848598003387451,
        "bert_recall": 0.934596061706543,
        "bert_f1": 0.9090481400489807,
        "meteor": 0.8892857142857143,
        "sbert_similarity": 0.7008299231529236
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose to use colors and patterns in her pottery project?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.060238842382440407,
        "bleu2": 0.02129764696972561,
        "bleu3": 0.01706305179528683,
        "bleu4": 0.016182712188007015,
        "bert_precision": 0.8825768828392029,
        "bert_recall": 0.8720123171806335,
        "bert_f1": 0.8772627711296082,
        "meteor": 0.052631578947368425,
        "sbert_similarity": 0.041106488555669785
      }
    },
    {
      "sample_id": 0,
      "question": "Is Oscar Melanie's pet?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8480530381202698,
        "bert_recall": 0.8904052376747131,
        "bert_f1": 0.8687132596969604,
        "meteor": 0.0,
        "sbert_similarity": 0.11724156141281128
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oscar hide his bone once?",
      "prediction": "Not mentioned in the conversation",
      "reference": "In Melanie's slipper",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.22222222222222224,
        "rouge2_f": 0.0,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8764923810958862,
        "bert_recall": 0.831631064414978,
        "bert_f1": 0.8534726500511169,
        "meteor": 0.15625,
        "sbert_similarity": 0.17263296246528625
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Melanie used to do with her dad?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Horseback riding",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8533901572227478,
        "bert_recall": 0.7734709978103638,
        "bert_f1": 0.8114676475524902,
        "meteor": 0.0,
        "sbert_similarity": 0.056279320269823074
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie make for a local church?",
      "prediction": "Not mentioned in the conversation or a stained glass window",
      "reference": "a stained glass window",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.5,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.4,
        "bleu2": 0.36514837167011077,
        "bleu3": 0.3254992452916931,
        "bleu4": 0.2626909894424158,
        "bert_precision": 0.8805418610572815,
        "bert_recall": 0.9368811249732971,
        "bert_f1": 0.9078382253646851,
        "meteor": 0.8627717391304348,
        "sbert_similarity": 0.6843292117118835
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie find in her neighborhood during her walk?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a rainbow sidewalk",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8700211644172668,
        "bert_recall": 0.8560808300971985,
        "bert_f1": 0.8629946708679199,
        "meteor": 0.0,
        "sbert_similarity": -0.04855124279856682
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Melanie to be courageous?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Brave by Sara Bareilles",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8708803057670593,
        "bert_recall": 0.8365832567214966,
        "bert_f1": 0.8533873558044434,
        "meteor": 0.0,
        "sbert_similarity": -0.0043097082525491714
      }
    },
    {
      "sample_id": 0,
      "question": "What type of instrument does Caroline play?",
      "prediction": "Not mentioned in the conversation",
      "reference": "clarinet and violin",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8583569526672363,
        "bert_recall": 0.7918203473091125,
        "bert_f1": 0.8237472772598267,
        "meteor": 0.0,
        "sbert_similarity": 0.012888428755104542
      }
    },
    {
      "sample_id": 0,
      "question": "Which classical musicians does Caroline enjoy listening to?",
      "prediction": "\"Not mentioned in the conversation\"",
      "reference": "Bach and Mozart",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8498205542564392,
        "bert_recall": 0.809005618095398,
        "bert_f1": 0.8289110064506531,
        "meteor": 0.0,
        "sbert_similarity": 0.13444994390010834
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Caroline a fan of in terms of modern music?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Ed Sheeran",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8636481761932373,
        "bert_recall": 0.7347403764724731,
        "bert_f1": 0.7939961552619934,
        "meteor": 0.0,
        "sbert_similarity": 0.09608782082796097
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Caroline see at the caf\u00e9?",
      "prediction": "Not mentioned in the conversation",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.12500000000000003,
        "rouge1_f": 0.12500000000000003,
        "rouge2_f": 0.0,
        "rougeL_f": 0.12500000000000003,
        "bleu1": 0.060238842382440407,
        "bleu2": 0.02129764696972561,
        "bleu3": 0.01706305179528683,
        "bleu4": 0.016182712188007015,
        "bert_precision": 0.8804165124893188,
        "bert_recall": 0.8307622671127319,
        "bert_f1": 0.8548689484596252,
        "meteor": 0.04807692307692308,
        "sbert_similarity": 0.09248805046081543
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Caroline face recently?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.886946439743042,
        "bert_recall": 0.8621915578842163,
        "bert_f1": 0.874393880367279,
        "meteor": 0.0,
        "sbert_similarity": 0.037741709500551224
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline do to keep herself busy during her pottery break?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Read a book and paint.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8759547472000122,
        "bert_recall": 0.8547960519790649,
        "bert_f1": 0.865246057510376,
        "meteor": 0.0,
        "sbert_similarity": 0.08983369171619415
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Melanie attended about?",
      "prediction": "Not mentioned in the conversation",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8824484348297119,
        "bert_recall": 0.8453162908554077,
        "bert_f1": 0.8634833097457886,
        "meteor": 0.0,
        "sbert_similarity": 0.0863410234451294
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Caroline's son on their road trip?",
      "prediction": "He got into an accident",
      "reference": "He got into an accident",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.996,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's son handle the accident?",
      "prediction": "Not mentioned in the conversation",
      "reference": "He was scared but reassured by his family",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.875566840171814,
        "bert_recall": 0.8454296588897705,
        "bert_f1": 0.8602343797683716,
        "meteor": 0.0,
        "sbert_similarity": 0.12110546976327896
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel about her family after the accident?",
      "prediction": "They are important and mean the world to her",
      "reference": "They are important and mean the world to her",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's children handle the accident?",
      "prediction": "Not mentioned in the conversation",
      "reference": "They were scared but resilient",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8781699538230896,
        "bert_recall": 0.8506824970245361,
        "bert_f1": 0.8642076849937439,
        "meteor": 0.0,
        "sbert_similarity": 0.07462236285209656
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel after the accident?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Grateful and thankful for her family",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8705779314041138,
        "bert_recall": 0.819611668586731,
        "bert_f1": 0.844326376914978,
        "meteor": 0.0,
        "sbert_similarity": 0.012023890390992165
      }
    },
    {
      "sample_id": 0,
      "question": "What was Caroline's reaction to her children enjoying the Grand Canyon?",
      "prediction": "She was happy and thankful",
      "reference": "She was happy and thankful",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline do after the road trip to relax?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Went on a nature walk or hike",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8826772570610046,
        "bert_recall": 0.8326032161712646,
        "bert_f1": 0.8569092750549316,
        "meteor": 0.0,
        "sbert_similarity": 0.0687059536576271
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline love most about camping with her family?",
      "prediction": "Being present and bonding with her family",
      "reference": "Being present and bonding with her family",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.9985422740524781,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 1,
      "question": "When Jon has lost his job as a banker?",
      "prediction": "20-jan-23",
      "reference": "19 January, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8276630640029907,
        "bert_recall": 0.834683895111084,
        "bert_f1": 0.8311586380004883,
        "meteor": 0.0,
        "sbert_similarity": 0.4994014501571655
      }
    },
    {
      "sample_id": 1,
      "question": "When Gina has lost her job at Door Dash?",
      "prediction": "20 January, 2023",
      "reference": "January, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8,
        "rouge1_f": 0.8,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.8,
        "bleu1": 0.75,
        "bleu2": 0.7071067811865475,
        "bleu3": 0.63287829698514,
        "bleu4": 0.3976353643835253,
        "bert_precision": 0.8992694020271301,
        "bert_recall": 0.9358680844306946,
        "bert_f1": 0.9172038435935974,
        "meteor": 0.8928571428571429,
        "sbert_similarity": 0.8815089464187622
      }
    },
    {
      "sample_id": 1,
      "question": "How do Jon and Gina both like to destress?",
      "prediction": "Go get 'em, Jon!",
      "reference": "by dancing",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8030148148536682,
        "bert_recall": 0.8346819877624512,
        "bert_f1": 0.8185422420501709,
        "meteor": 0.0,
        "sbert_similarity": 0.1290987730026245
      }
    },
    {
      "sample_id": 1,
      "question": "What do Jon and Gina both have in common?",
      "prediction": "Collaboration and motivation",
      "reference": "They lost their jobs and decided to start their own businesses.",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.15384615384615383,
        "rouge1_f": 0.14285714285714288,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14285714285714288,
        "bleu1": 0.016595689455954646,
        "bleu2": 0.006427482888174239,
        "bleu3": 0.006030129537982302,
        "bleu4": 0.005656903127920845,
        "bert_precision": 0.7929661273956299,
        "bert_recall": 0.842438817024231,
        "bert_f1": 0.8169541358947754,
        "meteor": 0.049019607843137254,
        "sbert_similarity": 0.1461704969406128
      }
    },
    {
      "sample_id": 1,
      "question": "Why did Jon decide to start his dance studio?",
      "prediction": "To teach others the joy that dancing brings him.",
      "reference": "He lost his job and decided to start his own business to share his passion.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809525,
        "rouge1_f": 0.08333333333333334,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08333333333333334,
        "bleu1": 0.10976232721880529,
        "bleu2": 0.025871228631744656,
        "bleu3": 0.0172124814651208,
        "bleu4": 0.013774415388612389,
        "bert_precision": 0.88973069190979,
        "bert_recall": 0.877137303352356,
        "bert_f1": 0.8833891153335571,
        "meteor": 0.034722222222222224,
        "sbert_similarity": 0.3127211034297943
      }
    },
    {
      "sample_id": 1,
      "question": "What Jon thinks the ideal dance studio should look like?",
      "prediction": "a dance studio by the water",
      "reference": "By the water, with natural light and Marley flooring",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.3076923076923077,
        "rougeL_f": 0.4,
        "bleu1": 0.256708559516296,
        "bleu2": 0.2296071157937954,
        "bleu3": 0.19104269976548732,
        "bleu4": 0.10373672493717558,
        "bert_precision": 0.8830963373184204,
        "bert_recall": 0.8382951021194458,
        "bert_f1": 0.860112726688385,
        "meteor": 0.21551724137931036,
        "sbert_similarity": 0.4614501893520355
      }
    },
    {
      "sample_id": 1,
      "question": "When is Jon's group performing at a festival?",
      "prediction": "20-jan-2023",
      "reference": "February, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8585913181304932,
        "bert_recall": 0.9136857986450195,
        "bert_f1": 0.8852822184562683,
        "meteor": 0.0,
        "sbert_similarity": 0.8056877851486206
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina launch an ad campaign for her store?",
      "prediction": "29-Jan-23",
      "reference": "29 January, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8296197056770325,
        "bert_recall": 0.8332445621490479,
        "bert_f1": 0.8314282298088074,
        "meteor": 0.0,
        "sbert_similarity": 0.5577459931373596
      }
    },
    {
      "sample_id": 1,
      "question": "When was Jon in Paris?",
      "prediction": "29-Jan-2023",
      "reference": "28 January 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.9084045886993408,
        "bert_recall": 0.9545073509216309,
        "bert_f1": 0.9308854937553406,
        "meteor": 0.0,
        "sbert_similarity": 0.8758574724197388
      }
    },
    {
      "sample_id": 1,
      "question": "Which city have both Jean and John visited?",
      "prediction": "Paris",
      "reference": "Rome",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.9993389844894409,
        "bert_recall": 0.9993389844894409,
        "bert_f1": 0.9993389844894409,
        "meteor": 0.0,
        "sbert_similarity": 0.5529642701148987
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina team up with a local artist for some cool designs?",
      "prediction": "5j21",
      "reference": "February, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8121839761734009,
        "bert_recall": 0.830600380897522,
        "bert_f1": 0.8212889432907104,
        "meteor": 0.0,
        "sbert_similarity": 0.15019533038139343
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina get her tattoo?",
      "prediction": "9feb2023",
      "reference": "A few years ago",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7932756543159485,
        "bert_recall": 0.8156579732894897,
        "bert_f1": 0.8043110966682434,
        "meteor": 0.0,
        "sbert_similarity": 0.1265423446893692
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon start to go to the gym?",
      "prediction": "2:35 pm 16-Mar-23",
      "reference": "March, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7960723638534546,
        "bert_recall": 0.8181279897689819,
        "bert_f1": 0.8069495558738708,
        "meteor": 0.0,
        "sbert_similarity": 0.28431692719459534
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina open her online clothing store?",
      "prediction": "3-apr-2023",
      "reference": "16 March, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8551906943321228,
        "bert_recall": 0.891664445400238,
        "bert_f1": 0.8730468153953552,
        "meteor": 0.0,
        "sbert_similarity": 0.6087161302566528
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon start expanding his studio's social media presence?",
      "prediction": "5:july,2023",
      "reference": "April, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8783648014068604,
        "bert_recall": 0.9420297145843506,
        "bert_f1": 0.9090839624404907,
        "meteor": 0.0,
        "sbert_similarity": 0.7758125066757202
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon host a dance competition?",
      "prediction": "1:26 pm on 3 April, 2023",
      "reference": "May, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.22222222222222224,
        "rouge2_f": 0.0,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.2182178902359924,
        "bleu3": 0.1006949130683619,
        "bleu4": 0.06985342056580097,
        "bert_precision": 0.8088476061820984,
        "bert_recall": 0.8684819936752319,
        "bert_f1": 0.8376047611236572,
        "meteor": 0.20833333333333334,
        "sbert_similarity": 0.7009459733963013
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon go to a fair to get more exposure for his dance studio?",
      "prediction": "8:29 pm on 13 June, 2023",
      "reference": "24 April, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.2182178902359924,
        "bleu3": 0.1006949130683619,
        "bleu4": 0.06985342056580097,
        "bert_precision": 0.850872278213501,
        "bert_recall": 0.9015390276908875,
        "bert_f1": 0.875473141670227,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.7504134178161621
      }
    },
    {
      "sample_id": 1,
      "question": "Why did Gina decide to start her own clothing store?",
      "prediction": "To grow the business and launch an ad campaign.",
      "reference": "She always loved fashion trends and finding unique pieces and she lost her job so decided it was time to start her own business.",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.18181818181818182,
        "rouge2_f": 0.0,
        "rougeL_f": 0.12121212121212122,
        "bleu1": 0.08925206405937193,
        "bleu2": 0.014875344009895321,
        "bleu3": 0.008796671020711393,
        "bleu4": 0.006659868297790407,
        "bert_precision": 0.8894103169441223,
        "bert_recall": 0.8554327487945557,
        "bert_f1": 0.8720906972885132,
        "meteor": 0.044444444444444446,
        "sbert_similarity": 0.279386967420578
      }
    },
    {
      "sample_id": 1,
      "question": "Do Jon and Gina start businesses out of what they love?",
      "prediction": "Starting your own business sounds awesome!",
      "reference": "Yes",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7951416969299316,
        "bert_recall": 0.8336696624755859,
        "bert_f1": 0.8139500021934509,
        "meteor": 0.0,
        "sbert_similarity": 0.017292702570557594
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina interview for a design internship?",
      "prediction": "3-14-May-2023",
      "reference": "10 May, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8798108696937561,
        "bert_recall": 0.9179942607879639,
        "bert_f1": 0.8984971642494202,
        "meteor": 0.0,
        "sbert_similarity": 0.8022323846817017
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina get accepted for the design internship?",
      "prediction": "27 May",
      "reference": "27 May, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8,
        "rouge1_f": 0.8,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.8,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.36787944117144233,
        "bleu3": 0.1720701423929801,
        "bleu4": 0.11633369384516798,
        "bert_precision": 0.9259932041168213,
        "bert_recall": 0.8484135270118713,
        "bert_f1": 0.8855074644088745,
        "meteor": 0.17241379310344826,
        "sbert_similarity": 0.7367979884147644
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon start reading \"The Lean Startup\"?",
      "prediction": "27-May-23",
      "reference": "May, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7886543869972229,
        "bert_recall": 0.827471911907196,
        "bert_f1": 0.8075969815254211,
        "meteor": 0.0,
        "sbert_similarity": 0.5019586682319641
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina develop a video presentation to teach how to style her fashion pieces? ",
      "prediction": "8june2023",
      "reference": "June, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.857272744178772,
        "bert_recall": 0.9147666692733765,
        "bert_f1": 0.8850870132446289,
        "meteor": 0.0,
        "sbert_similarity": 0.2202739119529724
      }
    },
    {
      "sample_id": 1,
      "question": "How did Gina promote her clothes store?",
      "prediction": "Speaker Ginasays : I just launched an ad campaign for my clothing store in hopes of growing the business.",
      "reference": "worked with an artist to make unique fashion pieces, made limited-edition sweatshirts, got some new offers and promotions for online store, developed a video presentation showing how to style her pieces",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.125,
        "rouge1_f": 0.12000000000000002,
        "rouge2_f": 0.0,
        "rougeL_f": 0.12000000000000002,
        "bleu1": 0.07448779556871142,
        "bleu2": 0.01395284249313058,
        "bleu3": 0.008469843058275419,
        "bleu4": 0.006293582369778947,
        "bert_precision": 0.8585969805717468,
        "bert_recall": 0.8540814518928528,
        "bert_f1": 0.8563332557678223,
        "meteor": 0.050335570469798654,
        "sbert_similarity": 0.4835452139377594
      }
    },
    {
      "sample_id": 1,
      "question": "Which events has Jon participated in to promote his business venture?",
      "prediction": "Attending networking events",
      "reference": "fair, networking events, dance competition",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.3333333333333333,
        "rougeL_f": 0.5,
        "bleu1": 0.17573142541048448,
        "bleu2": 0.15218787864872976,
        "bleu3": 0.08580066951771924,
        "bleu4": 0.06333742121977234,
        "bert_precision": 0.8711087107658386,
        "bert_recall": 0.8696386814117432,
        "bert_f1": 0.870373010635376,
        "meteor": 0.10416666666666666,
        "sbert_similarity": 0.601783812046051
      }
    },
    {
      "sample_id": 1,
      "question": "What does Jon's dance studio offer?",
      "prediction": "Support for dancers.",
      "reference": "one-on-one metoring and training to dancers,  workshops and classes to local schools and centers",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714288,
        "rouge1_f": 0.10526315789473684,
        "rouge2_f": 0.0,
        "rougeL_f": 0.10526315789473684,
        "bleu1": 0.015981965301676893,
        "bleu2": 0.005835788605995528,
        "bleu3": 0.004900275135249993,
        "bleu4": 0.005136146045581821,
        "bert_precision": 0.9126994609832764,
        "bert_recall": 0.815841794013977,
        "bert_f1": 0.8615569472312927,
        "meteor": 0.0,
        "sbert_similarity": 0.6193244457244873
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon receive mentorship to promote his venture?",
      "prediction": "9:jun:2023",
      "reference": "15 June, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8763130903244019,
        "bert_recall": 0.8887120485305786,
        "bert_f1": 0.8824689984321594,
        "meteor": 0.0,
        "sbert_similarity": 0.5847904086112976
      }
    },
    {
      "sample_id": 1,
      "question": "Did Jon and Gina both participate in dance competitions?",
      "prediction": "No",
      "reference": "Yes",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.999269425868988,
        "bert_recall": 0.999269425868988,
        "bert_f1": 0.999269425868988,
        "meteor": 0.0,
        "sbert_similarity": 0.7334951162338257
      }
    },
    {
      "sample_id": 1,
      "question": "When was Jon in Rome?",
      "prediction": "6-jun-2023",
      "reference": "June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8452185988426208,
        "bert_recall": 0.9386758804321289,
        "bert_f1": 0.8894991278648376,
        "meteor": 0.0,
        "sbert_similarity": 0.7670790553092957
      }
    },
    {
      "sample_id": 1,
      "question": "Which cities has Jon visited?",
      "prediction": "Paris",
      "reference": "Paris, Rome",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.04279677428117006,
        "bleu3": 0.02960813390314045,
        "bleu4": 0.024066394763145416,
        "bert_precision": 0.9136620163917542,
        "bert_recall": 0.8320091366767883,
        "bert_f1": 0.8709259629249573,
        "meteor": 0.0,
        "sbert_similarity": 0.8385129570960999
      }
    },
    {
      "sample_id": 1,
      "question": "When Jon is planning to open his dance studio?",
      "prediction": "9-feb-23",
      "reference": "20 June, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8217922449111938,
        "bert_recall": 0.8305836319923401,
        "bert_f1": 0.8261644840240479,
        "meteor": 0.0,
        "sbert_similarity": 0.3547607660293579
      }
    },
    {
      "sample_id": 1,
      "question": "How long did it take for Jon to open his studio?",
      "prediction": "not specified",
      "reference": "six months",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8503645658493042,
        "bert_recall": 0.8777822256088257,
        "bert_f1": 0.8638559579849243,
        "meteor": 0.0,
        "sbert_similarity": 0.24962425231933594
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina design a limited collection of hoodies?",
      "prediction": "21-jun-23",
      "reference": "June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7721171379089355,
        "bert_recall": 0.826687216758728,
        "bert_f1": 0.7984708547592163,
        "meteor": 0.0,
        "sbert_similarity": 0.4041730463504791
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon visit networking events for his store?",
      "prediction": "21-June-2023",
      "reference": "20 June, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.9257990717887878,
        "bert_recall": 0.9379864931106567,
        "bert_f1": 0.9318529963493347,
        "meteor": 0.0,
        "sbert_similarity": 0.8815740346908569
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina start being recognized by fashion editors?",
      "prediction": "1july2023",
      "reference": "July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8515545725822449,
        "bert_recall": 0.9224442839622498,
        "bert_f1": 0.8855830430984497,
        "meteor": 0.0,
        "sbert_similarity": 0.321340948343277
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon start learning marketing and analytics tools?",
      "prediction": "9-jun-2023",
      "reference": "July, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8630390167236328,
        "bert_recall": 0.9224010705947876,
        "bert_f1": 0.8917332291603088,
        "meteor": 0.0,
        "sbert_similarity": 0.7235622406005859
      }
    },
    {
      "sample_id": 1,
      "question": "When did Jon and Gina decide to collaborate to create dance content?",
      "prediction": "5:jul23",
      "reference": "21 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8458029627799988,
        "bert_recall": 0.8505983352661133,
        "bert_f1": 0.848193883895874,
        "meteor": 0.0,
        "sbert_similarity": 0.3560648262500763
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina mention Shia Labeouf?",
      "prediction": "DATE OF CONVERSATION: 23-July-2023",
      "reference": " 23 July, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8544490337371826,
        "bert_recall": 0.9128797650337219,
        "bert_f1": 0.8826984763145447,
        "meteor": 0.0,
        "sbert_similarity": 0.664759635925293
      }
    },
    {
      "sample_id": 1,
      "question": "When did Gina go to a dance class with a group of friends?",
      "prediction": "4apr2023",
      "reference": "21 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8834291696548462,
        "bert_recall": 0.915897011756897,
        "bert_f1": 0.8993701338768005,
        "meteor": 0.0,
        "sbert_similarity": 0.2715177834033966
      }
    },
    {
      "sample_id": 1,
      "question": "What is Gina's favorite style of dance?",
      "prediction": "Contemporary",
      "reference": "Contemporary",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.5,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 1,
      "question": "What is Jon's favorite style of dance?",
      "prediction": "contemporary",
      "reference": "Contemporary",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.997711181640625,
        "bert_recall": 0.997711181640625,
        "bert_f1": 0.997711181640625,
        "meteor": 0.5,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 1,
      "question": "What was Gina's favorite dancing memory?",
      "prediction": "Can't wait to make more memories at your dance studio!",
      "reference": "Winning first place at a regionals dance competition",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.22222222222222224,
        "rouge1_f": 0.2105263157894737,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2105263157894737,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.03892494720807617,
        "bleu3": 0.025677367760996977,
        "bleu4": 0.020255986027125642,
        "bert_precision": 0.8491460680961609,
        "bert_recall": 0.8598843216896057,
        "bert_f1": 0.8544814586639404,
        "meteor": 0.12195121951219512,
        "sbert_similarity": 0.38650190830230713
      }
    },
    {
      "sample_id": 1,
      "question": "What kind of dance piece did Gina's team perform to win first place?",
      "prediction": "Contemporary",
      "reference": "\"Finding Freedom\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8818063735961914,
        "bert_recall": 0.8446967601776123,
        "bert_f1": 0.8628527522087097,
        "meteor": 0.0,
        "sbert_similarity": 0.127860888838768
      }
    },
    {
      "sample_id": 1,
      "question": "What do the dancers in the photo represent?",
      "prediction": "a group of dancers on a stage with a man in the middle of the group",
      "reference": "They are performing at the festival",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352942,
        "rouge1_f": 0.09090909090909091,
        "rouge2_f": 0.0,
        "rougeL_f": 0.09090909090909091,
        "bleu1": 0.0625,
        "bleu2": 0.02041241452319315,
        "bleu3": 0.015007489164383502,
        "bleu4": 0.012300686288463768,
        "bert_precision": 0.8605536818504333,
        "bert_recall": 0.8933418393135071,
        "bert_f1": 0.8766412734985352,
        "meteor": 0.07142857142857144,
        "sbert_similarity": 0.2792479395866394
      }
    },
    {
      "sample_id": 1,
      "question": "What does Gina say about the dancers in the photo?",
      "prediction": "Yeah, I do remember those dance classes! I used to love spending time in the studio. That photo looks awesome, brings back lots of memories.",
      "reference": "They look graceful",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.07142857142857142,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07142857142857142,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8291838765144348,
        "bert_recall": 0.8591221570968628,
        "bert_f1": 0.8438875079154968,
        "meteor": 0.09615384615384615,
        "sbert_similarity": 0.1685350388288498
      }
    },
    {
      "sample_id": 1,
      "question": "What is Jon's attitude towards being part of the dance festival?",
      "prediction": "Yeah, they're the ones performing at the festival! They've been practicing hard and will definitely impress with their grace and skill.",
      "reference": "Glad",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8019179105758667,
        "bert_recall": 0.8230154514312744,
        "bert_f1": 0.8123297095298767,
        "meteor": 0.0,
        "sbert_similarity": 0.15819266438484192
      }
    },
    {
      "sample_id": 1,
      "question": "What kind of flooring is Jon looking for in his dance studio?",
      "prediction": "Marley flooring",
      "reference": "Marley flooring",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 1,
      "question": "What did Gina find for her clothing store on 1 February, 2023?",
      "prediction": "[]",
      "reference": "The perfect spot for her store",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8149658441543579,
        "bert_recall": 0.8057160973548889,
        "bert_f1": 0.8103145360946655,
        "meteor": 0.0,
        "sbert_similarity": 0.04810846969485283
      }
    },
    {
      "sample_id": 1,
      "question": "What did Gina design for her store?",
      "prediction": "A clothing store with a lot of clothes on display, cozy and inviting space, furniture that looks great and is comfy, and a chandelier matching the store's style.",
      "reference": "the space, furniture, and decor",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.27586206896551724,
        "rouge1_f": 0.2352941176470588,
        "rouge2_f": 0.0625,
        "rougeL_f": 0.17647058823529413,
        "bleu1": 0.18181818181818182,
        "bleu2": 0.13055824196677338,
        "bleu3": 0.08400042332382202,
        "bleu4": 0.036794373247613636,
        "bert_precision": 0.8384261727333069,
        "bert_recall": 0.9012544751167297,
        "bert_f1": 0.8687058091163635,
        "meteor": 0.2054794520547945,
        "sbert_similarity": 0.42002859711647034
      }
    },
    {
      "sample_id": 1,
      "question": "What did Gina want her customers to feel in her store?",
      "prediction": "Just creating an experience that'll make 'em wanna come back.",
      "reference": "cozy and comfortable",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8348824977874756,
        "bert_recall": 0.8473178744316101,
        "bert_f1": 0.8410542011260986,
        "meteor": 0.0,
        "sbert_similarity": 0.10211475938558578
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon say about Gina's progress with her store?",
      "prediction": "Wow, Gina! You found the perfect spot for your store. Way to go, hard work's paying off!",
      "reference": "hard work's paying off",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.38095238095238093,
        "rouge1_f": 0.4347826086956522,
        "rouge2_f": 0.38095238095238093,
        "rougeL_f": 0.4347826086956522,
        "bleu1": 0.21739130434782608,
        "bleu2": 0.19881069312188604,
        "bleu3": 0.18117066348451036,
        "bleu4": 0.15415064977510756,
        "bert_precision": 0.8647587299346924,
        "bert_recall": 0.9282693266868591,
        "bert_f1": 0.895389199256897,
        "meteor": 0.5555555555555556,
        "sbert_similarity": 0.37911269068717957
      }
    },
    {
      "sample_id": 1,
      "question": "What made Gina choose the furniture and decor for her store?",
      "prediction": "Chosen for looking great and being comfy, with a focus on style matching the store.",
      "reference": "personal style and customer comfort",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1,
        "bleu1": 0.11764705882352941,
        "bleu2": 0.027116307227332027,
        "bleu3": 0.017693837921724947,
        "bleu4": 0.013679192123121896,
        "bert_precision": 0.8703246116638184,
        "bert_recall": 0.8913577795028687,
        "bert_f1": 0.8807156085968018,
        "meteor": 0.1666666666666667,
        "sbert_similarity": 0.5984916687011719
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon say about creating a special experience for customers?",
      "prediction": "Creating a special experience for customers is the key to making them feel welcome and coming back.",
      "reference": "It's the key to making them feel welcome and coming back",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7142857142857143,
        "rouge1_f": 0.6896551724137931,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.6896551724137931,
        "bleu1": 0.5555555555555556,
        "bleu2": 0.5423261445466404,
        "bleu3": 0.5312171149021805,
        "bleu4": 0.5118285025257894,
        "bert_precision": 0.9236623644828796,
        "bert_recall": 0.953974187374115,
        "bert_f1": 0.9385735988616943,
        "meteor": 0.7753299276287782,
        "sbert_similarity": 0.5605942606925964
      }
    },
    {
      "sample_id": 1,
      "question": "What did Gina say about creating an experience for her customers?",
      "prediction": "Wow, Jon! Mentors can really help. I'm working on my online store, growing the customer base.",
      "reference": "making them want to come back",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8586553931236267,
        "bert_recall": 0.8357528448104858,
        "bert_f1": 0.8470494151115417,
        "meteor": 0.07142857142857144,
        "sbert_similarity": 0.07767491042613983
      }
    },
    {
      "sample_id": 1,
      "question": "How is Gina's store doing?",
      "prediction": "Gina's store looks great.",
      "reference": "The store is doing great.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444445,
        "rouge1_f": 0.4000000000000001,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4000000000000001,
        "bleu1": 0.5,
        "bleu2": 0.316227766016838,
        "bleu3": 0.1384586850774637,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9420990943908691,
        "bert_recall": 0.9414410591125488,
        "bert_f1": 0.9417699575424194,
        "meteor": 0.20408163265306123,
        "sbert_similarity": 0.5124073028564453
      }
    },
    {
      "sample_id": 1,
      "question": "What does Gina's tattoo symbolize?",
      "prediction": "Freedom",
      "reference": "Freedom and expressing herself through dance",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.006737946999085467,
        "bleu2": 0.002130725927060655,
        "bleu3": 0.0014741021868805238,
        "bleu4": 0.0011981952414407235,
        "bert_precision": 0.8796955943107605,
        "bert_recall": 0.813474178314209,
        "bert_f1": 0.8452898859977722,
        "meteor": 0.0909090909090909,
        "sbert_similarity": 0.5314433574676514
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon and Gina compare their entrepreneurial journeys to?",
      "prediction": "starting their own business",
      "reference": "dancing together and supporting each other",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8623585104942322,
        "bert_recall": 0.8550177812576294,
        "bert_f1": 0.8586724996566772,
        "meteor": 0.0,
        "sbert_similarity": 0.1259753257036209
      }
    },
    {
      "sample_id": 1,
      "question": "What advice does Gina give to Jon about running a successful business?",
      "prediction": "Can't wait to see what we can do together!",
      "reference": "build relationships with customers, create a strong brand image, stay positive",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8292348384857178,
        "bert_recall": 0.8358219265937805,
        "bert_f1": 0.8325153589248657,
        "meteor": 0.0,
        "sbert_similarity": 0.18865741789340973
      }
    },
    {
      "sample_id": 1,
      "question": "Why did Jon shut down his bank account?",
      "prediction": "Because he needed to do it for his biz.",
      "reference": "for his business",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.2,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.2,
        "bleu2": 0.14907119849998599,
        "bleu3": 0.06705330284284157,
        "bleu4": 0.0446323613785333,
        "bert_precision": 0.8710457682609558,
        "bert_recall": 0.9062737226486206,
        "bert_f1": 0.8883106708526611,
        "meteor": 0.5208333333333335,
        "sbert_similarity": 0.5708503127098083
      }
    },
    {
      "sample_id": 1,
      "question": "Why did Gina combine her clothing business with dance?",
      "prediction": "To show her creativity and share her love for dance with others, and to add dance-inspired items to her store.",
      "reference": "she is passionate about dance and fashion",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.18181818181818182,
        "rouge1_f": 0.14285714285714285,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14285714285714285,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.020806259464411975,
        "bleu3": 0.013510398157576722,
        "bleu4": 0.010331208012220438,
        "bert_precision": 0.8738035559654236,
        "bert_recall": 0.8928463459014893,
        "bert_f1": 0.8832222819328308,
        "meteor": 0.18072289156626506,
        "sbert_similarity": 0.6801803708076477
      }
    },
    {
      "sample_id": 1,
      "question": "What does Jon's dance make him?",
      "prediction": "Jon's dance makes him happy.",
      "reference": "happy",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.33333333333333337,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.838874101638794,
        "bert_recall": 0.8375475406646729,
        "bert_f1": 0.8382103443145752,
        "meteor": 0.0,
        "sbert_similarity": 0.2870074212551117
      }
    },
    {
      "sample_id": 1,
      "question": "What did Gina receive from a dance contest?",
      "prediction": "a trophy with a glass globe on top",
      "reference": "a trophy",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444445,
        "rouge1_f": 0.4,
        "rouge2_f": 0.25,
        "rougeL_f": 0.4,
        "bleu1": 0.25,
        "bleu2": 0.18898223650461357,
        "bleu3": 0.08622792534209149,
        "bleu4": 0.05873949094699214,
        "bert_precision": 0.849531352519989,
        "bert_recall": 0.9521528482437134,
        "bert_f1": 0.8979195952415466,
        "meteor": 0.3846153846153847,
        "sbert_similarity": 0.7098019123077393
      }
    },
    {
      "sample_id": 1,
      "question": "How does Gina stay confident in her business?",
      "prediction": "Having confidence in yourself is important for making it successful!",
      "reference": "By reminding herself of her successes and progress, having a support system, and focusing on why she started",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.07407407407407408,
        "rouge1_f": 0.14285714285714285,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07142857142857142,
        "bleu1": 0.040112106159998544,
        "bleu2": 0.013303680568361875,
        "bleu3": 0.009910796001679474,
        "bleu4": 0.008317385975693101,
        "bert_precision": 0.854459822177887,
        "bert_recall": 0.8490602970123291,
        "bert_f1": 0.8517515063285828,
        "meteor": 0.029069767441860465,
        "sbert_similarity": 0.3090074360370636
      }
    },
    {
      "sample_id": 1,
      "question": "What kind of professional experience did Gina get accepted for on May 23, 2023?",
      "prediction": "fashion internship",
      "reference": "fashion internship",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 1,
      "question": "Where is Gina's fashion internship?",
      "prediction": "in the fashion department of an international company.",
      "reference": "fashion department of an international company",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8571428571428571,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8333333333333333,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.6454972243679028,
        "bleu3": 0.6227700724866008,
        "bleu4": 0.5873949094699213,
        "bert_precision": 0.9447154402732849,
        "bert_recall": 0.9617636203765869,
        "bert_f1": 0.9531632661819458,
        "meteor": 0.8032258064516131,
        "sbert_similarity": 0.8849791288375854
      }
    },
    {
      "sample_id": 1,
      "question": "What book is Jon currently reading?",
      "prediction": "the book",
      "reference": "The Lean Startup",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.13562437855552414,
        "bleu3": 0.10556327625176448,
        "bleu4": 0.09069748827745895,
        "bert_precision": 0.8934599161148071,
        "bert_recall": 0.9056239128112793,
        "bert_f1": 0.8995007872581482,
        "meteor": 0.17241379310344826,
        "sbert_similarity": 0.18019649386405945
      }
    },
    {
      "sample_id": 1,
      "question": "What is Jon offering to the dancers at his dance studio?",
      "prediction": "The joy that dancing brings them",
      "reference": "One-on-one mentoring and training",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8454493880271912,
        "bert_recall": 0.8245329856872559,
        "bert_f1": 0.8348602056503296,
        "meteor": 0.0,
        "sbert_similarity": 0.10650787502527237
      }
    },
    {
      "sample_id": 1,
      "question": "How does Jon use the clipboard with a notepad attached to it?",
      "prediction": "I also use whiteboard to stay on track, visualize goals and tokenize successes.",
      "reference": "To set goals, track achievements, and find areas for improvement",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.34782608695652173,
        "rouge1_f": 0.34782608695652173,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2608695652173913,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.02733546260131627,
        "bleu4": 0.019765441873349214,
        "bert_precision": 0.8914496898651123,
        "bert_recall": 0.9105968475341797,
        "bert_f1": 0.9009215831756592,
        "meteor": 0.09708737864077671,
        "sbert_similarity": 0.4899384081363678
      }
    },
    {
      "sample_id": 1,
      "question": "What does Jon tell Gina he won't do?",
      "prediction": "Jon tells Gina he won't quit.",
      "reference": "quit",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.04225771273642583,
        "bleu3": 0.032085442892067474,
        "bleu4": 0.02777619034011792,
        "bert_precision": 0.8268181085586548,
        "bert_recall": 0.8658446073532104,
        "bert_f1": 0.845881462097168,
        "meteor": 0.0,
        "sbert_similarity": 0.3787461221218109
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon take a trip to Rome for?",
      "prediction": "Jon took a trip to Rome to clear his mind.",
      "reference": "To clear his mind",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6153846153846153,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.5,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.36363636363636365,
        "bleu2": 0.33028912953790823,
        "bleu3": 0.293028657606374,
        "bleu4": 0.23462350320528,
        "bert_precision": 0.900143027305603,
        "bert_recall": 0.9452531933784485,
        "bert_f1": 0.922146737575531,
        "meteor": 0.640096618357488,
        "sbert_similarity": 0.39489224553108215
      }
    },
    {
      "sample_id": 1,
      "question": "What is Jon working on opening?",
      "prediction": "The official opening night",
      "reference": "a dance studio",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8584122657775879,
        "bert_recall": 0.8740277290344238,
        "bert_f1": 0.8661496639251709,
        "meteor": 0.0,
        "sbert_similarity": 0.20704174041748047
      }
    },
    {
      "sample_id": 1,
      "question": "How does Gina describe the studio that Jon has opened?",
      "prediction": "The studio looks amazing.",
      "reference": "amazing",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8560417294502258,
        "bert_recall": 0.848974347114563,
        "bert_f1": 0.8524933457374573,
        "meteor": 0.0,
        "sbert_similarity": 0.30061963200569153
      }
    },
    {
      "sample_id": 1,
      "question": "How does Jon feel about the opening night of his dance studio?",
      "prediction": "Can't wait to see it all come together!",
      "reference": "excited",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7802282571792603,
        "bert_recall": 0.8350617289543152,
        "bert_f1": 0.8067142963409424,
        "meteor": 0.0,
        "sbert_similarity": 0.2915375232696533
      }
    },
    {
      "sample_id": 1,
      "question": "How does Gina describe the feeling that dance brings?",
      "prediction": "Dance brings me joy.",
      "reference": "magical",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8576026558876038,
        "bert_recall": 0.848685085773468,
        "bert_f1": 0.8531205654144287,
        "meteor": 0.0,
        "sbert_similarity": 0.23436246812343597
      }
    },
    {
      "sample_id": 1,
      "question": "What does Jon plan to do at the grand opening of his dance studio?",
      "prediction": "Can't wait to see it all come together!",
      "reference": "savor all the good vibes",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.15384615384615385,
        "rouge1_f": 0.14285714285714285,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14285714285714285,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.03333333333333335,
        "bleu3": 0.024950558772614845,
        "bleu4": 0.021105340631872645,
        "bert_precision": 0.8385617136955261,
        "bert_recall": 0.8443276882171631,
        "bert_f1": 0.8414347767829895,
        "meteor": 0.09433962264150944,
        "sbert_similarity": 0.25067588686943054
      }
    },
    {
      "sample_id": 1,
      "question": "What does Gina say to Jon about the grand opening?",
      "prediction": "Can't wait for tomorrow's grand opening!",
      "reference": "Let's live it up and make some great memories",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.11111111111111112,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11111111111111112,
        "bleu1": 0.09942659075715217,
        "bleu2": 0.03334869235560668,
        "bleu3": 0.025115566621621982,
        "bleu4": 0.02145851237135921,
        "bert_precision": 0.8463375568389893,
        "bert_recall": 0.858250081539154,
        "bert_f1": 0.8522521257400513,
        "meteor": 0.0,
        "sbert_similarity": 0.19021053612232208
      }
    },
    {
      "sample_id": 1,
      "question": "What is the general sentiment about the upcoming grand opening?",
      "prediction": "Can't wait for tomorrow's grand opening!",
      "reference": "excitement",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7781696319580078,
        "bert_recall": 0.8339396715164185,
        "bert_f1": 0.8050899505615234,
        "meteor": 0.0,
        "sbert_similarity": 0.284410685300827
      }
    },
    {
      "sample_id": 1,
      "question": "What did Gina make a limited edition line of?",
      "prediction": "Gina made a limited edition line of a hoodie.",
      "reference": "Hoodies",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.19999999999999998,
        "rouge2_f": 0.0,
        "rougeL_f": 0.19999999999999998,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8272560834884644,
        "bert_recall": 0.8070892095565796,
        "bert_f1": 0.8170482516288757,
        "meteor": 0.0,
        "sbert_similarity": 0.5540645718574524
      }
    },
    {
      "sample_id": 1,
      "question": "According to Gina, what makes Jon a perfect mentor and guide?",
      "prediction": "Loving what Jon does and bringing joy to others is so rewarding. His positivity and determination will make the dance studio a hit.",
      "reference": "His positivity and determination",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3076923076923077,
        "rouge1_f": 0.29629629629629634,
        "rouge2_f": 0.24000000000000002,
        "rougeL_f": 0.29629629629629634,
        "bleu1": 0.15999999999999998,
        "bleu2": 0.1414213562373095,
        "bleu3": 0.12283145922513826,
        "bleu4": 0.09429254736980938,
        "bert_precision": 0.8547073602676392,
        "bert_recall": 0.9058312773704529,
        "bert_f1": 0.8795270323753357,
        "meteor": 0.6726694915254238,
        "sbert_similarity": 0.31708964705467224
      }
    },
    {
      "sample_id": 1,
      "question": "What temporary job did Jon take to cover expenses?",
      "prediction": "Not Mentioned",
      "reference": "Not mentioned",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9186702370643616,
        "bert_recall": 0.9495305418968201,
        "bert_f1": 0.9338455200195312,
        "meteor": 0.9375,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 1,
      "question": "What plans does Jon have after receiving advice at the networking event?",
      "prediction": "I've had some tough times with my business, Jon. Sourcing trendy pieces for my store was a big hurdle. I had to do a lot of research and networking. My advice? Don't be scared to reach out to people in your field for help and contacts. Networking was a lifesaver for me and opened me up to amazing products that I might not have found otherwise.",
      "reference": "Sprucing up his business plan, tweaking his pitch to investors, and working on an online platform.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.12307692307692307,
        "rouge1_f": 0.09523809523809523,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07142857142857142,
        "bleu1": 0.07999999999999999,
        "bleu2": 0.010397504898200722,
        "bleu3": 0.005575408390965018,
        "bleu4": 0.003787047284389884,
        "bert_precision": 0.8417127132415771,
        "bert_recall": 0.8559825420379639,
        "bert_f1": 0.8487876653671265,
        "meteor": 0.07142857142857142,
        "sbert_similarity": 0.27703824639320374
      }
    },
    {
      "sample_id": 1,
      "question": "What offer does Gina make to Jon regarding social media?",
      "prediction": "\"No offer is mentioned regarding social media.\"",
      "reference": "Helping with making content and managing his social media accounts.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.22222222222222224,
        "rouge1_f": 0.23529411764705882,
        "rouge2_f": 0.13333333333333333,
        "rougeL_f": 0.23529411764705882,
        "bleu1": 0.27145122541078787,
        "bleu2": 0.16519995491100892,
        "bleu3": 0.06935868363730253,
        "bleu4": 0.04469338322542863,
        "bert_precision": 0.8724849820137024,
        "bert_recall": 0.8767817616462708,
        "bert_f1": 0.8746281266212463,
        "meteor": 0.05154639175257732,
        "sbert_similarity": 0.3608643412590027
      }
    },
    {
      "sample_id": 1,
      "question": "What is Jon's favorite style of painting?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Contemporary",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8525497317314148,
        "bert_recall": 0.8956478834152222,
        "bert_f1": 0.8735675811767578,
        "meteor": 0.0,
        "sbert_similarity": 0.23356103897094727
      }
    },
    {
      "sample_id": 1,
      "question": "What was Jon's favorite dancing memory?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Winning first place at a regionals dance competition",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8873941898345947,
        "bert_recall": 0.8396360278129578,
        "bert_f1": 0.8628547787666321,
        "meteor": 0.0,
        "sbert_similarity": 0.04511777311563492
      }
    },
    {
      "sample_id": 1,
      "question": "What kind of dance piece did Jon's team perform to win first place?",
      "prediction": "\"Not mentioned in the conversation\"",
      "reference": "\"Finding Freedom\"",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.06900655593423542,
        "bleu3": 0.047098549390932394,
        "bleu4": 0.039281465090051315,
        "bert_precision": 0.8817017078399658,
        "bert_recall": 0.8907642364501953,
        "bert_f1": 0.8862097859382629,
        "meteor": 0.0,
        "sbert_similarity": 0.056174732744693756
      }
    },
    {
      "sample_id": 1,
      "question": "What is Gina's attitude towards participating in the dance festival?",
      "prediction": "Glad",
      "reference": "Glad",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 1,
      "question": "What kind of flooring is Gina looking for in her dance studio?",
      "prediction": "Not mentioned in the conversation or Marley flooring",
      "reference": "Marley flooring",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.25,
        "rougeL_f": 0.4,
        "bleu1": 0.25,
        "bleu2": 0.18898223650461357,
        "bleu3": 0.08622792534209149,
        "bleu4": 0.05873949094699214,
        "bert_precision": 0.8666609525680542,
        "bert_recall": 0.8990276455879211,
        "bert_f1": 0.8825476169586182,
        "meteor": 0.7211538461538463,
        "sbert_similarity": 0.7641513347625732
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon find for his clothing store on 1 February, 2023?",
      "prediction": "Not mentioned in the conversation",
      "reference": "The perfect spot for her store",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1818181818181818,
        "rouge1_f": 0.1818181818181818,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1818181818181818,
        "bleu1": 0.1637461506155964,
        "bleu2": 0.05789300674674099,
        "bleu3": 0.046382183633183686,
        "bleu4": 0.0439891724758422,
        "bert_precision": 0.8696539402008057,
        "bert_recall": 0.8438922166824341,
        "bert_f1": 0.8565794229507446,
        "meteor": 0.0847457627118644,
        "sbert_similarity": 0.09485948830842972
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon design for his store?",
      "prediction": "the space, furniture, and decor",
      "reference": "the space, furniture, and decor",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon want his customers to feel in her store?",
      "prediction": "Not mentioned in the conversation",
      "reference": "cozy and comfortable",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8714585900306702,
        "bert_recall": 0.8514558672904968,
        "bert_f1": 0.8613410592079163,
        "meteor": 0.0,
        "sbert_similarity": 0.1293993443250656
      }
    },
    {
      "sample_id": 1,
      "question": "What made Jon choose the furniture and decor for his store?",
      "prediction": "Not mentioned in the conversation or personal style and customer comfort",
      "reference": "personal style and customer comfort",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.625,
        "rouge1_f": 0.625,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.625,
        "bleu1": 0.45454545454545453,
        "bleu2": 0.4264014327112209,
        "bleu3": 0.3964882289652318,
        "bleu4": 0.3508439695638686,
        "bert_precision": 0.8941164612770081,
        "bert_recall": 0.9440189003944397,
        "bert_f1": 0.9183903336524963,
        "meteor": 0.8892857142857143,
        "sbert_similarity": 0.720145583152771
      }
    },
    {
      "sample_id": 1,
      "question": "How is Jon's store doing?",
      "prediction": "The store is doing great.",
      "reference": "The store is doing great.",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.000000238418579,
        "bert_recall": 1.000000238418579,
        "bert_f1": 1.000000238418579,
        "meteor": 0.996,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 1,
      "question": "What does Jon's tattoo symbolize?",
      "prediction": "Freedom and expressing himself through dance",
      "reference": "Freedom and expressing himself through dance",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 1,
      "question": "Why did Gina shut down her bank account?",
      "prediction": "Not mentioned in the conversation",
      "reference": "for her business",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8748558163642883,
        "bert_recall": 0.8663439154624939,
        "bert_f1": 0.8705790042877197,
        "meteor": 0.0,
        "sbert_similarity": 0.11508052796125412
      }
    },
    {
      "sample_id": 1,
      "question": "Why did Jon combine his clothing business with dance?",
      "prediction": "he is passionate about dance and fashion",
      "reference": "he is passionate about dance and fashion",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.9985422740524781,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 1,
      "question": "What did Gina receive from a dance contest?",
      "prediction": "trophy",
      "reference": "a trophy",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.11633369384516798,
        "bleu3": 0.08048325236348887,
        "bleu4": 0.06541924356118012,
        "bert_precision": 0.9223119020462036,
        "bert_recall": 0.8657370805740356,
        "bert_f1": 0.8931294679641724,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.923323392868042
      }
    },
    {
      "sample_id": 1,
      "question": "What kind of professional experience did Jon get accepted for on May 23, 2023?",
      "prediction": "Not mentioned in the conversation",
      "reference": "fashion internship",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8793139457702637,
        "bert_recall": 0.881193220615387,
        "bert_f1": 0.8802525997161865,
        "meteor": 0.0,
        "sbert_similarity": 0.03995119035243988
      }
    },
    {
      "sample_id": 1,
      "question": "Where is Gina's HR internship?",
      "prediction": "fashion department of an international company",
      "reference": "fashion department of an international company",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 1,
      "question": "Where is Jon's fashion internship?",
      "prediction": "Not mentioned in the conversation",
      "reference": "fashion department of an international company",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8809700012207031,
        "bert_recall": 0.8474488854408264,
        "bert_f1": 0.8638843894004822,
        "meteor": 0.0,
        "sbert_similarity": 0.08578399568796158
      }
    },
    {
      "sample_id": 1,
      "question": "What book is Gina currently reading?",
      "prediction": "Not mentioned in the conversation",
      "reference": "The Lean Startup",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.85880446434021,
        "bert_recall": 0.9001353979110718,
        "bert_f1": 0.8789843320846558,
        "meteor": 0.15625,
        "sbert_similarity": 0.1566043198108673
      }
    },
    {
      "sample_id": 1,
      "question": "How does Gina use the clipboard with a notepad attached to it?",
      "prediction": "Not mentioned in the conversation",
      "reference": "To set goals, track achievements, and find areas for improvement",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8866156339645386,
        "bert_recall": 0.8510011434555054,
        "bert_f1": 0.8684434294700623,
        "meteor": 0.0,
        "sbert_similarity": 0.05664966627955437
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon take a trip to Barcelona for?",
      "prediction": "Not mentioned in the conversation",
      "reference": "To clear his mind",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8808639645576477,
        "bert_recall": 0.8639194965362549,
        "bert_f1": 0.8723095059394836,
        "meteor": 0.0,
        "sbert_similarity": 0.1768544465303421
      }
    },
    {
      "sample_id": 1,
      "question": "What did Jon make a limited edition line of?",
      "prediction": "Hoodies",
      "reference": "Hoodies",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 1,
      "question": "What temporary job did Gina take to cover expenses?",
      "prediction": "Not Mentioned",
      "reference": "Not mentioned",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9186702370643616,
        "bert_recall": 0.9495305418968201,
        "bert_f1": 0.9338455200195312,
        "meteor": 0.9375,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 1,
      "question": "What plans does Gina have after receiving advice at the networking event?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Sprucing up her business plan, tweaking her pitch to investors, and working on an online platform.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8793408870697021,
        "bert_recall": 0.8351776003837585,
        "bert_f1": 0.8566904067993164,
        "meteor": 0.0,
        "sbert_similarity": 0.1292829066514969
      }
    }
  ]
}